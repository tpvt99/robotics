Logging to D:\GitHub\robotics\cs287hw5\hw5_release_v2\ppo_tf2\run_scripts/data/pg+baseline_HalfCheetah/02

 ---------------- Iteration 0 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 0           |
| ItrTime                 | 17.5        |
| LossAfter               | -0.5191884  |
| LossBefore              | 0.004647876 |
| Time                    | 17.5        |
| Time-Optimization       | 0.302       |
| Time-SampleProc         | 0.0584      |
| Time-Sampling           | 17.1        |
| n_timesteps             | 10000       |
| train-AverageDiscoun... | -27.8       |
| train-AverageReturn     | -43.1       |
| train-EnvExecTime       | 2.56        |
| train-MaxReturn         | 26.7        |
| train-MinReturn         | -173        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.3        |
| train-StdReturn         | 37.3        |
-----------------------------------------

 ---------------- Iteration 1 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 1           |
| ItrTime                 | 16.6        |
| LossAfter               | -0.3249407  |
| LossBefore              | 0.011421973 |
| Time                    | 34.1        |
| Time-Optimization       | 0.243       |
| Time-SampleProc         | 0.027       |
| Time-Sampling           | 16.4        |
| n_timesteps             | 20000       |
| train-AverageDiscoun... | -22         |
| train-AverageReturn     | -34.2       |
| train-EnvExecTime       | 2.6         |
| train-MaxReturn         | 87.4        |
| train-MinReturn         | -145        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 13.5        |
| train-StdReturn         | 35.3        |
-----------------------------------------

 ---------------- Iteration 2 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 2           |
| ItrTime                 | 16.8        |
| LossAfter               | -0.1476072  |
| LossBefore              | 0.016441772 |
| Time                    | 51          |
| Time-Optimization       | 0.242       |
| Time-SampleProc         | 0.021       |
| Time-Sampling           | 16.6        |
| n_timesteps             | 30000       |
| train-AverageDiscoun... | -13.3       |
| train-AverageReturn     | -20.9       |
| train-EnvExecTime       | 2.58        |
| train-MaxReturn         | 56          |
| train-MinReturn         | -93.7       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 13.7        |
| train-StdReturn         | 29.9        |
-----------------------------------------

 ---------------- Iteration 3 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 3           |
| ItrTime                 | 17.7        |
| LossAfter               | -0.09093747 |
| LossBefore              | 0.04731704  |
| Time                    | 68.6        |
| Time-Optimization       | 0.303       |
| Time-SampleProc         | 0.027       |
| Time-Sampling           | 17.3        |
| n_timesteps             | 40000       |
| train-AverageDiscoun... | -16.7       |
| train-AverageReturn     | -25.6       |
| train-EnvExecTime       | 2.8         |
| train-MaxReturn         | 73.7        |
| train-MinReturn         | -120        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.3        |
| train-StdReturn         | 32.6        |
-----------------------------------------

 ---------------- Iteration 4 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 4            |
| ItrTime                 | 19.6         |
| LossAfter               | -0.16696106  |
| LossBefore              | -0.010173462 |
| Time                    | 88.2         |
| Time-Optimization       | 0.272        |
| Time-SampleProc         | 0.027        |
| Time-Sampling           | 19.3         |
| n_timesteps             | 50000        |
| train-AverageDiscoun... | -16.8        |
| train-AverageReturn     | -24.8        |
| train-EnvExecTime       | 3.15         |
| train-MaxReturn         | 59           |
| train-MinReturn         | -139         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 15.8         |
| train-StdReturn         | 37.8         |
------------------------------------------

 ---------------- Iteration 5 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 5            |
| ItrTime                 | 17.7         |
| LossAfter               | -0.28116813  |
| LossBefore              | -0.020367505 |
| Time                    | 106          |
| Time-Optimization       | 0.256        |
| Time-SampleProc         | 0.024        |
| Time-Sampling           | 17.4         |
| n_timesteps             | 60000        |
| train-AverageDiscoun... | -18.3        |
| train-AverageReturn     | -26.7        |
| train-EnvExecTime       | 2.76         |
| train-MaxReturn         | 71.7         |
| train-MinReturn         | -172         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.3         |
| train-StdReturn         | 43.6         |
------------------------------------------

 ---------------- Iteration 6 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 6             |
| ItrTime                 | 16.9          |
| LossAfter               | -0.1598082    |
| LossBefore              | -0.0037470215 |
| Time                    | 123           |
| Time-Optimization       | 0.237         |
| Time-SampleProc         | 0.026         |
| Time-Sampling           | 16.7          |
| n_timesteps             | 70000         |
| train-AverageDiscoun... | -10.7         |
| train-AverageReturn     | -15.6         |
| train-EnvExecTime       | 2.6           |
| train-MaxReturn         | 71.2          |
| train-MinReturn         | -113          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 13.8          |
| train-StdReturn         | 37            |
-------------------------------------------

 ---------------- Iteration 7 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 7            |
| ItrTime                 | 16.8         |
| LossAfter               | -0.23193872  |
| LossBefore              | -0.014792017 |
| Time                    | 140          |
| Time-Optimization       | 0.239        |
| Time-SampleProc         | 0.029        |
| Time-Sampling           | 16.5         |
| n_timesteps             | 80000        |
| train-AverageDiscoun... | -4.64        |
| train-AverageReturn     | -3.63        |
| train-EnvExecTime       | 2.57         |
| train-MaxReturn         | 99.1         |
| train-MinReturn         | -126         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.7         |
| train-StdReturn         | 38.3         |
------------------------------------------

 ---------------- Iteration 8 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 8            |
| ItrTime                 | 17.5         |
| LossAfter               | -0.21270981  |
| LossBefore              | -0.012934941 |
| Time                    | 157          |
| Time-Optimization       | 0.252        |
| Time-SampleProc         | 0.024        |
| Time-Sampling           | 17.2         |
| n_timesteps             | 90000        |
| train-AverageDiscoun... | -5.51        |
| train-AverageReturn     | -2.01        |
| train-EnvExecTime       | 2.65         |
| train-MaxReturn         | 109          |
| train-MinReturn         | -98.4        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.3         |
| train-StdReturn         | 40.9         |
------------------------------------------

 ---------------- Iteration 9 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 9            |
| ItrTime                 | 18           |
| LossAfter               | -0.23163101  |
| LossBefore              | -0.027363177 |
| Time                    | 175          |
| Time-Optimization       | 0.244        |
| Time-SampleProc         | 0.021        |
| Time-Sampling           | 17.7         |
| n_timesteps             | 100000       |
| train-AverageDiscoun... | -10.3        |
| train-AverageReturn     | -11.2        |
| train-EnvExecTime       | 2.7          |
| train-MaxReturn         | 93.1         |
| train-MinReturn         | -147         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.7         |
| train-StdReturn         | 49.4         |
------------------------------------------

 ---------------- Iteration 10 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 10           |
| ItrTime                 | 17.7         |
| LossAfter               | -0.25405273  |
| LossBefore              | -0.013788135 |
| Time                    | 193          |
| Time-Optimization       | 0.24         |
| Time-SampleProc         | 0.03         |
| Time-Sampling           | 17.4         |
| n_timesteps             | 110000       |
| train-AverageDiscoun... | -16.3        |
| train-AverageReturn     | -22.6        |
| train-EnvExecTime       | 2.57         |
| train-MaxReturn         | 105          |
| train-MinReturn         | -129         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.6         |
| train-StdReturn         | 48.4         |
------------------------------------------

 ---------------- Iteration 11 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 11            |
| ItrTime                 | 17.1          |
| LossAfter               | -0.18940854   |
| LossBefore              | -0.0047133057 |
| Time                    | 210           |
| Time-Optimization       | 0.245         |
| Time-SampleProc         | 0.028         |
| Time-Sampling           | 16.9          |
| n_timesteps             | 120000        |
| train-AverageDiscoun... | -18           |
| train-AverageReturn     | -26.4         |
| train-EnvExecTime       | 2.63          |
| train-MaxReturn         | 43.4          |
| train-MinReturn         | -147          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 13.9          |
| train-StdReturn         | 40.3          |
-------------------------------------------

 ---------------- Iteration 12 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 12           |
| ItrTime                 | 16.9         |
| LossAfter               | -0.21634866  |
| LossBefore              | -0.017299872 |
| Time                    | 227          |
| Time-Optimization       | 0.234        |
| Time-SampleProc         | 0.022        |
| Time-Sampling           | 16.7         |
| n_timesteps             | 130000       |
| train-AverageDiscoun... | -27          |
| train-AverageReturn     | -41.1        |
| train-EnvExecTime       | 2.57         |
| train-MaxReturn         | 76.2         |
| train-MinReturn         | -132         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.8         |
| train-StdReturn         | 40.6         |
------------------------------------------

 ---------------- Iteration 13 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 13          |
| ItrTime                 | 17.8        |
| LossAfter               | -0.11660437 |
| LossBefore              | 0.03164736  |
| Time                    | 245         |
| Time-Optimization       | 0.244       |
| Time-SampleProc         | 0.028       |
| Time-Sampling           | 17.5        |
| n_timesteps             | 140000      |
| train-AverageDiscoun... | -22.6       |
| train-AverageReturn     | -33.4       |
| train-EnvExecTime       | 2.73        |
| train-MaxReturn         | 34.8        |
| train-MinReturn         | -192        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.5        |
| train-StdReturn         | 43.1        |
-----------------------------------------

 ---------------- Iteration 14 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 14           |
| ItrTime                 | 17.9         |
| LossAfter               | -0.07746472  |
| LossBefore              | 0.0073908204 |
| Time                    | 263          |
| Time-Optimization       | 0.236        |
| Time-SampleProc         | 0.023        |
| Time-Sampling           | 17.6         |
| n_timesteps             | 150000       |
| train-AverageDiscoun... | -22.6        |
| train-AverageReturn     | -33.8        |
| train-EnvExecTime       | 2.76         |
| train-MaxReturn         | 37           |
| train-MinReturn         | -145         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.6         |
| train-StdReturn         | 38.2         |
------------------------------------------

 ---------------- Iteration 15 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 15          |
| ItrTime                 | 17.7        |
| LossAfter               | -0.18214433 |
| LossBefore              | 0.021955078 |
| Time                    | 280         |
| Time-Optimization       | 0.327       |
| Time-SampleProc         | 0.031       |
| Time-Sampling           | 17.4        |
| n_timesteps             | 160000      |
| train-AverageDiscoun... | -19.2       |
| train-AverageReturn     | -28.8       |
| train-EnvExecTime       | 2.7         |
| train-MaxReturn         | 36.8        |
| train-MinReturn         | -132        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.4        |
| train-StdReturn         | 35.4        |
-----------------------------------------

 ---------------- Iteration 16 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 16           |
| ItrTime                 | 18.3         |
| LossAfter               | -0.3754704   |
| LossBefore              | -0.005338037 |
| Time                    | 299          |
| Time-Optimization       | 0.281        |
| Time-SampleProc         | 0.021        |
| Time-Sampling           | 18           |
| n_timesteps             | 170000       |
| train-AverageDiscoun... | -22.6        |
| train-AverageReturn     | -34.2        |
| train-EnvExecTime       | 2.82         |
| train-MaxReturn         | 41           |
| train-MinReturn         | -134         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.9         |
| train-StdReturn         | 37.4         |
------------------------------------------

 ---------------- Iteration 17 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 17           |
| ItrTime                 | 17.7         |
| LossAfter               | -0.67282856  |
| LossBefore              | -0.009722705 |
| Time                    | 316          |
| Time-Optimization       | 0.236        |
| Time-SampleProc         | 0.021        |
| Time-Sampling           | 17.4         |
| n_timesteps             | 180000       |
| train-AverageDiscoun... | -21.5        |
| train-AverageReturn     | -34.1        |
| train-EnvExecTime       | 2.8          |
| train-MaxReturn         | 59.6         |
| train-MinReturn         | -178         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.3         |
| train-StdReturn         | 41.4         |
------------------------------------------

 ---------------- Iteration 18 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 18           |
| ItrTime                 | 18.6         |
| LossAfter               | -0.7717208   |
| LossBefore              | 0.0056646974 |
| Time                    | 335          |
| Time-Optimization       | 0.281        |
| Time-SampleProc         | 0.031        |
| Time-Sampling           | 18.3         |
| n_timesteps             | 190000       |
| train-AverageDiscoun... | -20.5        |
| train-AverageReturn     | -32.2        |
| train-EnvExecTime       | 2.88         |
| train-MaxReturn         | 58.5         |
| train-MinReturn         | -149         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 15.1         |
| train-StdReturn         | 41.6         |
------------------------------------------

 ---------------- Iteration 19 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 19           |
| ItrTime                 | 17.9         |
| LossAfter               | -0.7217861   |
| LossBefore              | -0.020377172 |
| Time                    | 353          |
| Time-Optimization       | 0.263        |
| Time-SampleProc         | 0.026        |
| Time-Sampling           | 17.6         |
| n_timesteps             | 200000       |
| train-AverageDiscoun... | -15.2        |
| train-AverageReturn     | -22          |
| train-EnvExecTime       | 2.8          |
| train-MaxReturn         | 104          |
| train-MinReturn         | -102         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.5         |
| train-StdReturn         | 36.4         |
------------------------------------------

 ---------------- Iteration 20 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 20           |
| ItrTime                 | 18           |
| LossAfter               | -0.90369445  |
| LossBefore              | -0.009078466 |
| Time                    | 371          |
| Time-Optimization       | 0.24         |
| Time-SampleProc         | 0.026        |
| Time-Sampling           | 17.7         |
| n_timesteps             | 210000       |
| train-AverageDiscoun... | -8.75        |
| train-AverageReturn     | -9.16        |
| train-EnvExecTime       | 2.74         |
| train-MaxReturn         | 84.8         |
| train-MinReturn         | -108         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.7         |
| train-StdReturn         | 39           |
------------------------------------------

 ---------------- Iteration 21 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 21          |
| ItrTime                 | 17.3        |
| LossAfter               | -1.417993   |
| LossBefore              | 0.007479004 |
| Time                    | 388         |
| Time-Optimization       | 0.247       |
| Time-SampleProc         | 0.022       |
| Time-Sampling           | 17          |
| n_timesteps             | 220000      |
| train-AverageDiscoun... | -9.7        |
| train-AverageReturn     | -12.4       |
| train-EnvExecTime       | 2.59        |
| train-MaxReturn         | 90          |
| train-MinReturn         | -130        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.2        |
| train-StdReturn         | 45.9        |
-----------------------------------------

 ---------------- Iteration 22 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 22            |
| ItrTime                 | 17.5          |
| LossAfter               | -1.3185167    |
| LossBefore              | -0.0003713501 |
| Time                    | 406           |
| Time-Optimization       | 0.235         |
| Time-SampleProc         | 0.025         |
| Time-Sampling           | 17.3          |
| n_timesteps             | 230000        |
| train-AverageDiscoun... | -15.5         |
| train-AverageReturn     | -22.4         |
| train-EnvExecTime       | 2.63          |
| train-MaxReturn         | 84.9          |
| train-MinReturn         | -125          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.4          |
| train-StdReturn         | 47.4          |
-------------------------------------------

 ---------------- Iteration 23 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 23           |
| ItrTime                 | 17.4         |
| LossAfter               | -1.277292    |
| LossBefore              | -0.020664979 |
| Time                    | 423          |
| Time-Optimization       | 0.241        |
| Time-SampleProc         | 0.029        |
| Time-Sampling           | 17.2         |
| n_timesteps             | 240000       |
| train-AverageDiscoun... | -21.2        |
| train-AverageReturn     | -31.7        |
| train-EnvExecTime       | 2.54         |
| train-MaxReturn         | 110          |
| train-MinReturn         | -141         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.3         |
| train-StdReturn         | 50.4         |
------------------------------------------

 ---------------- Iteration 24 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 24            |
| ItrTime                 | 16.8          |
| LossAfter               | -1.2444364    |
| LossBefore              | 0.00025057374 |
| Time                    | 440           |
| Time-Optimization       | 0.23          |
| Time-SampleProc         | 0.023         |
| Time-Sampling           | 16.6          |
| n_timesteps             | 250000        |
| train-AverageDiscoun... | -10.7         |
| train-AverageReturn     | -12.4         |
| train-EnvExecTime       | 2.62          |
| train-MaxReturn         | 88.8          |
| train-MinReturn         | -104          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 13.7          |
| train-StdReturn         | 44.2          |
-------------------------------------------

 ---------------- Iteration 25 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 25           |
| ItrTime                 | 17.2         |
| LossAfter               | -0.17300878  |
| LossBefore              | -0.006728931 |
| Time                    | 457          |
| Time-Optimization       | 0.252        |
| Time-SampleProc         | 0.024        |
| Time-Sampling           | 16.9         |
| n_timesteps             | 260000       |
| train-AverageDiscoun... | -119         |
| train-AverageReturn     | -207         |
| train-EnvExecTime       | 2.55         |
| train-MaxReturn         | 17.5         |
| train-MinReturn         | -285         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 50.1         |
------------------------------------------

 ---------------- Iteration 26 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 26           |
| ItrTime                 | 17.3         |
| LossAfter               | -0.2011861   |
| LossBefore              | -0.013604334 |
| Time                    | 475          |
| Time-Optimization       | 0.237        |
| Time-SampleProc         | 0.026        |
| Time-Sampling           | 17           |
| n_timesteps             | 270000       |
| train-AverageDiscoun... | -122         |
| train-AverageReturn     | -213         |
| train-EnvExecTime       | 2.49         |
| train-MaxReturn         | -54.3        |
| train-MinReturn         | -293         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.3         |
| train-StdReturn         | 45           |
------------------------------------------

 ---------------- Iteration 27 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 27            |
| ItrTime                 | 16.8          |
| LossAfter               | -1.5352386    |
| LossBefore              | -0.0007844055 |
| Time                    | 491           |
| Time-Optimization       | 0.247         |
| Time-SampleProc         | 0.022         |
| Time-Sampling           | 16.5          |
| n_timesteps             | 280000        |
| train-AverageDiscoun... | -98.1         |
| train-AverageReturn     | -174          |
| train-EnvExecTime       | 2.52          |
| train-MaxReturn         | 61.3          |
| train-MinReturn         | -290          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 13.7          |
| train-StdReturn         | 73.7          |
-------------------------------------------

 ---------------- Iteration 28 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 28            |
| ItrTime                 | 16.9          |
| LossAfter               | -2.3415878    |
| LossBefore              | -0.0014783936 |
| Time                    | 508           |
| Time-Optimization       | 0.242         |
| Time-SampleProc         | 0.029         |
| Time-Sampling           | 16.6          |
| n_timesteps             | 290000        |
| train-AverageDiscoun... | -19.4         |
| train-AverageReturn     | -30.3         |
| train-EnvExecTime       | 2.59          |
| train-MaxReturn         | 68.7          |
| train-MinReturn         | -143          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 13.7          |
| train-StdReturn         | 38.7          |
-------------------------------------------

 ---------------- Iteration 29 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 29          |
| ItrTime                 | 17.1        |
| LossAfter               | -1.7392106  |
| LossBefore              | 0.025895316 |
| Time                    | 525         |
| Time-Optimization       | 0.233       |
| Time-SampleProc         | 0.029       |
| Time-Sampling           | 16.8        |
| n_timesteps             | 300000      |
| train-AverageDiscoun... | -17.4       |
| train-AverageReturn     | -26.5       |
| train-EnvExecTime       | 2.58        |
| train-MaxReturn         | 54.3        |
| train-MinReturn         | -163        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14          |
| train-StdReturn         | 37.5        |
-----------------------------------------

 ---------------- Iteration 30 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
----------------------------------------
| Itr                     | 30         |
| ItrTime                 | 17.3       |
| LossAfter               | -1.1667216 |
| LossBefore              | 0.00539375 |
| Time                    | 543        |
| Time-Optimization       | 0.246      |
| Time-SampleProc         | 0.023      |
| Time-Sampling           | 17         |
| n_timesteps             | 310000     |
| train-AverageDiscoun... | -20        |
| train-AverageReturn     | -29.9      |
| train-EnvExecTime       | 2.62       |
| train-MaxReturn         | 120        |
| train-MinReturn         | -142       |
| train-NumTrajs          | 100        |
| train-PolicyExecTime    | 14.1       |
| train-StdReturn         | 42.7       |
----------------------------------------

 ---------------- Iteration 31 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 31          |
| ItrTime                 | 17.1        |
| LossAfter               | -0.47073936 |
| LossBefore              | 0.005631079 |
| Time                    | 560         |
| Time-Optimization       | 0.25        |
| Time-SampleProc         | 0.023       |
| Time-Sampling           | 16.8        |
| n_timesteps             | 320000      |
| train-AverageDiscoun... | -9.79       |
| train-AverageReturn     | -15.1       |
| train-EnvExecTime       | 2.6         |
| train-MaxReturn         | 121         |
| train-MinReturn         | -116        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 13.9        |
| train-StdReturn         | 44          |
-----------------------------------------

 ---------------- Iteration 32 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 32           |
| ItrTime                 | 17.4         |
| LossAfter               | -0.9940415   |
| LossBefore              | 0.0037398925 |
| Time                    | 577          |
| Time-Optimization       | 0.232        |
| Time-SampleProc         | 0.028        |
| Time-Sampling           | 17.1         |
| n_timesteps             | 330000       |
| train-AverageDiscoun... | -2.92        |
| train-AverageReturn     | -4.74        |
| train-EnvExecTime       | 2.62         |
| train-MaxReturn         | 153          |
| train-MinReturn         | -110         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 50.1         |
------------------------------------------

 ---------------- Iteration 33 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 33            |
| ItrTime                 | 16.6          |
| LossAfter               | -1.79033      |
| LossBefore              | -0.0027840333 |
| Time                    | 594           |
| Time-Optimization       | 0.251         |
| Time-SampleProc         | 0.029         |
| Time-Sampling           | 16.3          |
| n_timesteps             | 340000        |
| train-AverageDiscoun... | 0.758         |
| train-AverageReturn     | -0.136        |
| train-EnvExecTime       | 2.59          |
| train-MaxReturn         | 88.7          |
| train-MinReturn         | -86.5         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 13.4          |
| train-StdReturn         | 35.6          |
-------------------------------------------

 ---------------- Iteration 34 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 34           |
| ItrTime                 | 16.5         |
| LossAfter               | -0.23559414  |
| LossBefore              | -0.019730614 |
| Time                    | 610          |
| Time-Optimization       | 0.244        |
| Time-SampleProc         | 0.026        |
| Time-Sampling           | 16.2         |
| n_timesteps             | 350000       |
| train-AverageDiscoun... | 0.653        |
| train-AverageReturn     | -2.01        |
| train-EnvExecTime       | 2.61         |
| train-MaxReturn         | 115          |
| train-MinReturn         | -104         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.4         |
| train-StdReturn         | 39.2         |
------------------------------------------

 ---------------- Iteration 35 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 35          |
| ItrTime                 | 16.1        |
| LossAfter               | -0.8286703  |
| LossBefore              | 0.004718408 |
| Time                    | 626         |
| Time-Optimization       | 0.266       |
| Time-SampleProc         | 0.023       |
| Time-Sampling           | 15.8        |
| n_timesteps             | 360000      |
| train-AverageDiscoun... | -8.51       |
| train-AverageReturn     | -17.9       |
| train-EnvExecTime       | 2.58        |
| train-MaxReturn         | 106         |
| train-MinReturn         | -143        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 13          |
| train-StdReturn         | 39          |
-----------------------------------------

 ---------------- Iteration 36 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 36            |
| ItrTime                 | 16.3          |
| LossAfter               | -0.71252686   |
| LossBefore              | -0.0077006468 |
| Time                    | 643           |
| Time-Optimization       | 0.249         |
| Time-SampleProc         | 0.025         |
| Time-Sampling           | 16            |
| n_timesteps             | 370000        |
| train-AverageDiscoun... | -4.89         |
| train-AverageReturn     | -13.4         |
| train-EnvExecTime       | 2.53          |
| train-MaxReturn         | 131           |
| train-MinReturn         | -142          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 13.2          |
| train-StdReturn         | 43            |
-------------------------------------------

 ---------------- Iteration 37 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 37            |
| ItrTime                 | 16.9          |
| LossAfter               | -0.49879855   |
| LossBefore              | -0.0046753907 |
| Time                    | 660           |
| Time-Optimization       | 0.251         |
| Time-SampleProc         | 0.026         |
| Time-Sampling           | 16.6          |
| n_timesteps             | 380000        |
| train-AverageDiscoun... | -8.32         |
| train-AverageReturn     | -17.5         |
| train-EnvExecTime       | 2.56          |
| train-MaxReturn         | 91.7          |
| train-MinReturn         | -120          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 13.8          |
| train-StdReturn         | 39.4          |
-------------------------------------------

 ---------------- Iteration 38 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 38           |
| ItrTime                 | 16.5         |
| LossAfter               | -0.33151236  |
| LossBefore              | 0.0042509767 |
| Time                    | 676          |
| Time-Optimization       | 0.279        |
| Time-SampleProc         | 0.029        |
| Time-Sampling           | 16.2         |
| n_timesteps             | 390000       |
| train-AverageDiscoun... | 1.51         |
| train-AverageReturn     | -2.32        |
| train-EnvExecTime       | 2.54         |
| train-MaxReturn         | 179          |
| train-MinReturn         | -95.4        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.3         |
| train-StdReturn         | 50.3         |
------------------------------------------

 ---------------- Iteration 39 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 39           |
| ItrTime                 | 16.4         |
| LossAfter               | -0.44991708  |
| LossBefore              | 0.0041973875 |
| Time                    | 693          |
| Time-Optimization       | 0.259        |
| Time-SampleProc         | 0.031        |
| Time-Sampling           | 16.1         |
| n_timesteps             | 400000       |
| train-AverageDiscoun... | -2.8         |
| train-AverageReturn     | -8.66        |
| train-EnvExecTime       | 2.64         |
| train-MaxReturn         | 211          |
| train-MinReturn         | -90.9        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.2         |
| train-StdReturn         | 50.1         |
------------------------------------------

 ---------------- Iteration 40 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 40           |
| ItrTime                 | 16           |
| LossAfter               | -0.72136104  |
| LossBefore              | -0.012640039 |
| Time                    | 709          |
| Time-Optimization       | 0.253        |
| Time-SampleProc         | 0.029        |
| Time-Sampling           | 15.7         |
| n_timesteps             | 410000       |
| train-AverageDiscoun... | -4.46        |
| train-AverageReturn     | -10.7        |
| train-EnvExecTime       | 2.57         |
| train-MaxReturn         | 190          |
| train-MinReturn         | -101         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 12.9         |
| train-StdReturn         | 53.7         |
------------------------------------------

 ---------------- Iteration 41 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 41          |
| ItrTime                 | 16.8        |
| LossAfter               | -0.49980128 |
| LossBefore              | 0.013094287 |
| Time                    | 725         |
| Time-Optimization       | 0.262       |
| Time-SampleProc         | 0.028       |
| Time-Sampling           | 16.5        |
| n_timesteps             | 420000      |
| train-AverageDiscoun... | -4.82       |
| train-AverageReturn     | -11.5       |
| train-EnvExecTime       | 2.58        |
| train-MaxReturn         | 136         |
| train-MinReturn         | -153        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 13.7        |
| train-StdReturn         | 49.4        |
-----------------------------------------

 ---------------- Iteration 42 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 42          |
| ItrTime                 | 16.1        |
| LossAfter               | -0.6555917  |
| LossBefore              | 0.011647265 |
| Time                    | 742         |
| Time-Optimization       | 0.248       |
| Time-SampleProc         | 0.022       |
| Time-Sampling           | 15.8        |
| n_timesteps             | 430000      |
| train-AverageDiscoun... | -4.84       |
| train-AverageReturn     | -8.67       |
| train-EnvExecTime       | 2.49        |
| train-MaxReturn         | 193         |
| train-MinReturn         | -89.2       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 13.1        |
| train-StdReturn         | 50.1        |
-----------------------------------------

 ---------------- Iteration 43 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 43           |
| ItrTime                 | 15.8         |
| LossAfter               | -0.18621114  |
| LossBefore              | -0.006703586 |
| Time                    | 757          |
| Time-Optimization       | 0.244        |
| Time-SampleProc         | 0.027        |
| Time-Sampling           | 15.6         |
| n_timesteps             | 440000       |
| train-AverageDiscoun... | -8.92        |
| train-AverageReturn     | -11.7        |
| train-EnvExecTime       | 2.54         |
| train-MaxReturn         | 110          |
| train-MinReturn         | -139         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 12.8         |
| train-StdReturn         | 39.8         |
------------------------------------------

 ---------------- Iteration 44 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 44           |
| ItrTime                 | 15.9         |
| LossAfter               | -0.11836415  |
| LossBefore              | 0.0019970094 |
| Time                    | 773          |
| Time-Optimization       | 0.273        |
| Time-SampleProc         | 0.029        |
| Time-Sampling           | 15.6         |
| n_timesteps             | 450000       |
| train-AverageDiscoun... | -13.8        |
| train-AverageReturn     | -16.6        |
| train-EnvExecTime       | 2.53         |
| train-MaxReturn         | 148          |
| train-MinReturn         | -99.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 12.9         |
| train-StdReturn         | 44.5         |
------------------------------------------

 ---------------- Iteration 45 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 45          |
| ItrTime                 | 16.2        |
| LossAfter               | -0.10166822 |
| LossBefore              | -0.02046338 |
| Time                    | 789         |
| Time-Optimization       | 0.245       |
| Time-SampleProc         | 0.028       |
| Time-Sampling           | 15.9        |
| n_timesteps             | 460000      |
| train-AverageDiscoun... | -18.4       |
| train-AverageReturn     | -23.4       |
| train-EnvExecTime       | 2.52        |
| train-MaxReturn         | 119         |
| train-MinReturn         | -124        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 13.1        |
| train-StdReturn         | 42          |
-----------------------------------------

 ---------------- Iteration 46 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 46           |
| ItrTime                 | 16.9         |
| LossAfter               | -0.069922775 |
| LossBefore              | 0.016105322  |
| Time                    | 806          |
| Time-Optimization       | 0.247        |
| Time-SampleProc         | 0.028        |
| Time-Sampling           | 16.6         |
| n_timesteps             | 470000       |
| train-AverageDiscoun... | -15.2        |
| train-AverageReturn     | -19.1        |
| train-EnvExecTime       | 2.56         |
| train-MaxReturn         | 115          |
| train-MinReturn         | -148         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.8         |
| train-StdReturn         | 52.7         |
------------------------------------------

 ---------------- Iteration 47 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
----------------------------------------
| Itr                     | 47         |
| ItrTime                 | 16.4       |
| LossAfter               | -0.1439832 |
| LossBefore              | 0.00789458 |
| Time                    | 823        |
| Time-Optimization       | 0.273      |
| Time-SampleProc         | 0.023      |
| Time-Sampling           | 16.1       |
| n_timesteps             | 480000     |
| train-AverageDiscoun... | -20.8      |
| train-AverageReturn     | -28.3      |
| train-EnvExecTime       | 2.51       |
| train-MaxReturn         | 71.4       |
| train-MinReturn         | -149       |
| train-NumTrajs          | 100        |
| train-PolicyExecTime    | 13.3       |
| train-StdReturn         | 44.5       |
----------------------------------------

 ---------------- Iteration 48 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 48           |
| ItrTime                 | 16.4         |
| LossAfter               | -0.11632256  |
| LossBefore              | 0.0064515625 |
| Time                    | 839          |
| Time-Optimization       | 0.248        |
| Time-SampleProc         | 0.028        |
| Time-Sampling           | 16.1         |
| n_timesteps             | 490000       |
| train-AverageDiscoun... | -21.1        |
| train-AverageReturn     | -27.8        |
| train-EnvExecTime       | 2.59         |
| train-MaxReturn         | 66.4         |
| train-MinReturn         | -158         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.3         |
| train-StdReturn         | 45.6         |
------------------------------------------

 ---------------- Iteration 49 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 49           |
| ItrTime                 | 16.4         |
| LossAfter               | -0.088013455 |
| LossBefore              | -0.004394678 |
| Time                    | 856          |
| Time-Optimization       | 0.349        |
| Time-SampleProc         | 0.022        |
| Time-Sampling           | 16           |
| n_timesteps             | 500000       |
| train-AverageDiscoun... | -20.5        |
| train-AverageReturn     | -26.7        |
| train-EnvExecTime       | 2.57         |
| train-MaxReturn         | 86.1         |
| train-MinReturn         | -118         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.1         |
| train-StdReturn         | 45.9         |
------------------------------------------

 ---------------- Iteration 50 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 50            |
| ItrTime                 | 16            |
| LossAfter               | -0.18170276   |
| LossBefore              | -0.0049808077 |
| Time                    | 872           |
| Time-Optimization       | 0.249         |
| Time-SampleProc         | 0.024         |
| Time-Sampling           | 15.8          |
| n_timesteps             | 510000        |
| train-AverageDiscoun... | -25.2         |
| train-AverageReturn     | -35.9         |
| train-EnvExecTime       | 2.4           |
| train-MaxReturn         | 63.4          |
| train-MinReturn         | -156          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 13.1          |
| train-StdReturn         | 44            |
-------------------------------------------

 ---------------- Iteration 51 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 51          |
| ItrTime                 | 15.9        |
| LossAfter               | -0.11107339 |
| LossBefore              | 0.034153737 |
| Time                    | 888         |
| Time-Optimization       | 0.282       |
| Time-SampleProc         | 0.038       |
| Time-Sampling           | 15.6        |
| n_timesteps             | 520000      |
| train-AverageDiscoun... | -30.4       |
| train-AverageReturn     | -43.6       |
| train-EnvExecTime       | 2.56        |
| train-MaxReturn         | 52.6        |
| train-MinReturn         | -136        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 12.8        |
| train-StdReturn         | 44.6        |
-----------------------------------------

 ---------------- Iteration 52 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 52           |
| ItrTime                 | 16.4         |
| LossAfter               | -0.4510045   |
| LossBefore              | -0.016983984 |
| Time                    | 904          |
| Time-Optimization       | 0.26         |
| Time-SampleProc         | 0.022        |
| Time-Sampling           | 16.1         |
| n_timesteps             | 530000       |
| train-AverageDiscoun... | -46.1        |
| train-AverageReturn     | -72.7        |
| train-EnvExecTime       | 2.59         |
| train-MaxReturn         | 65.3         |
| train-MinReturn         | -195         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.2         |
| train-StdReturn         | 42.8         |
------------------------------------------

 ---------------- Iteration 53 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 53            |
| ItrTime                 | 17.1          |
| LossAfter               | -0.79205394   |
| LossBefore              | -0.0021260376 |
| Time                    | 921           |
| Time-Optimization       | 0.236         |
| Time-SampleProc         | 0.02          |
| Time-Sampling           | 16.8          |
| n_timesteps             | 540000        |
| train-AverageDiscoun... | -29.7         |
| train-AverageReturn     | -42.9         |
| train-EnvExecTime       | 2.6           |
| train-MaxReturn         | 95.3          |
| train-MinReturn         | -132          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14            |
| train-StdReturn         | 50.3          |
-------------------------------------------

 ---------------- Iteration 54 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 54             |
| ItrTime                 | 17.2           |
| LossAfter               | -0.19474404    |
| LossBefore              | -0.00071674807 |
| Time                    | 938            |
| Time-Optimization       | 0.235          |
| Time-SampleProc         | 0.029          |
| Time-Sampling           | 17             |
| n_timesteps             | 550000         |
| train-AverageDiscoun... | -22.2          |
| train-AverageReturn     | -29.2          |
| train-EnvExecTime       | 2.7            |
| train-MaxReturn         | 74             |
| train-MinReturn         | -181           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 14             |
| train-StdReturn         | 43.9           |
--------------------------------------------

 ---------------- Iteration 55 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 55          |
| ItrTime                 | 17.2        |
| LossAfter               | -0.14613178 |
| LossBefore              | 0.02799231  |
| Time                    | 956         |
| Time-Optimization       | 0.247       |
| Time-SampleProc         | 0.023       |
| Time-Sampling           | 17          |
| n_timesteps             | 560000      |
| train-AverageDiscoun... | -26.4       |
| train-AverageReturn     | -36.8       |
| train-EnvExecTime       | 2.58        |
| train-MaxReturn         | 84.4        |
| train-MinReturn         | -182        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 47.6        |
-----------------------------------------

 ---------------- Iteration 56 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 56           |
| ItrTime                 | 16.9         |
| LossAfter               | -0.27258417  |
| LossBefore              | 0.0077075684 |
| Time                    | 973          |
| Time-Optimization       | 0.249        |
| Time-SampleProc         | 0.028        |
| Time-Sampling           | 16.7         |
| n_timesteps             | 570000       |
| train-AverageDiscoun... | -25.9        |
| train-AverageReturn     | -37          |
| train-EnvExecTime       | 2.61         |
| train-MaxReturn         | 122          |
| train-MinReturn         | -216         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.8         |
| train-StdReturn         | 56.5         |
------------------------------------------

 ---------------- Iteration 57 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 57             |
| ItrTime                 | 16.9           |
| LossAfter               | -0.1911113     |
| LossBefore              | -0.00011485596 |
| Time                    | 989            |
| Time-Optimization       | 0.238          |
| Time-SampleProc         | 0.022          |
| Time-Sampling           | 16.6           |
| n_timesteps             | 580000         |
| train-AverageDiscoun... | -25.9          |
| train-AverageReturn     | -37.8          |
| train-EnvExecTime       | 2.61           |
| train-MaxReturn         | 105            |
| train-MinReturn         | -161           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 13.7           |
| train-StdReturn         | 46.7           |
--------------------------------------------

 ---------------- Iteration 58 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 58          |
| ItrTime                 | 17.2        |
| LossAfter               | -0.32422066 |
| LossBefore              | 0.014646009 |
| Time                    | 1.01e+03    |
| Time-Optimization       | 0.244       |
| Time-SampleProc         | 0.023       |
| Time-Sampling           | 16.9        |
| n_timesteps             | 590000      |
| train-AverageDiscoun... | -30.3       |
| train-AverageReturn     | -46.2       |
| train-EnvExecTime       | 2.55        |
| train-MaxReturn         | 59.1        |
| train-MinReturn         | -153        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 37.6        |
-----------------------------------------

 ---------------- Iteration 59 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 59           |
| ItrTime                 | 18.1         |
| LossAfter               | -0.614426    |
| LossBefore              | -0.008773309 |
| Time                    | 1.02e+03     |
| Time-Optimization       | 0.272        |
| Time-SampleProc         | 0.033        |
| Time-Sampling           | 17.7         |
| n_timesteps             | 600000       |
| train-AverageDiscoun... | -31.8        |
| train-AverageReturn     | -47.6        |
| train-EnvExecTime       | 2.74         |
| train-MaxReturn         | 80.8         |
| train-MinReturn         | -184         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.7         |
| train-StdReturn         | 48           |
------------------------------------------

 ---------------- Iteration 60 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 60           |
| ItrTime                 | 17.9         |
| LossAfter               | -0.79957753  |
| LossBefore              | -0.006768164 |
| Time                    | 1.04e+03     |
| Time-Optimization       | 0.262        |
| Time-SampleProc         | 0.021        |
| Time-Sampling           | 17.6         |
| n_timesteps             | 610000       |
| train-AverageDiscoun... | -36.9        |
| train-AverageReturn     | -58.6        |
| train-EnvExecTime       | 2.71         |
| train-MaxReturn         | 54.4         |
| train-MinReturn         | -189         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.5         |
| train-StdReturn         | 44.8         |
------------------------------------------

 ---------------- Iteration 61 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 61          |
| ItrTime                 | 17.5        |
| LossAfter               | -0.2790294  |
| LossBefore              | 0.006777594 |
| Time                    | 1.06e+03    |
| Time-Optimization       | 0.236       |
| Time-SampleProc         | 0.027       |
| Time-Sampling           | 17.2        |
| n_timesteps             | 620000      |
| train-AverageDiscoun... | -52         |
| train-AverageReturn     | -82.5       |
| train-EnvExecTime       | 2.58        |
| train-MaxReturn         | 5.61        |
| train-MinReturn         | -173        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.4        |
| train-StdReturn         | 36.8        |
-----------------------------------------

 ---------------- Iteration 62 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 62          |
| ItrTime                 | 16.9        |
| LossAfter               | -0.06679963 |
| LossBefore              | 0.03703486  |
| Time                    | 1.08e+03    |
| Time-Optimization       | 0.24        |
| Time-SampleProc         | 0.024       |
| Time-Sampling           | 16.7        |
| n_timesteps             | 630000      |
| train-AverageDiscoun... | -63.2       |
| train-AverageReturn     | -102        |
| train-EnvExecTime       | 2.59        |
| train-MaxReturn         | -22         |
| train-MinReturn         | -167        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 13.8        |
| train-StdReturn         | 31.2        |
-----------------------------------------

 ---------------- Iteration 63 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 63            |
| ItrTime                 | 16.8          |
| LossAfter               | -0.09125219   |
| LossBefore              | -0.0005886383 |
| Time                    | 1.09e+03      |
| Time-Optimization       | 0.24          |
| Time-SampleProc         | 0.028         |
| Time-Sampling           | 16.6          |
| n_timesteps             | 640000        |
| train-AverageDiscoun... | -64.7         |
| train-AverageReturn     | -103          |
| train-EnvExecTime       | 2.48          |
| train-MaxReturn         | -20.5         |
| train-MinReturn         | -203          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 13.8          |
| train-StdReturn         | 34.2          |
-------------------------------------------

 ---------------- Iteration 64 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 64          |
| ItrTime                 | 16.9        |
| LossAfter               | -0.13293523 |
| LossBefore              | 0.006960367 |
| Time                    | 1.11e+03    |
| Time-Optimization       | 0.243       |
| Time-SampleProc         | 0.022       |
| Time-Sampling           | 16.6        |
| n_timesteps             | 650000      |
| train-AverageDiscoun... | -60.2       |
| train-AverageReturn     | -97.4       |
| train-EnvExecTime       | 2.55        |
| train-MaxReturn         | -18.4       |
| train-MinReturn         | -197        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 13.8        |
| train-StdReturn         | 37.3        |
-----------------------------------------

 ---------------- Iteration 65 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 65           |
| ItrTime                 | 16.9         |
| LossAfter               | -0.106161915 |
| LossBefore              | 0.0015296631 |
| Time                    | 1.13e+03     |
| Time-Optimization       | 0.243        |
| Time-SampleProc         | 0.024        |
| Time-Sampling           | 16.7         |
| n_timesteps             | 660000       |
| train-AverageDiscoun... | -55.3        |
| train-AverageReturn     | -89.7        |
| train-EnvExecTime       | 2.56         |
| train-MaxReturn         | -3.82        |
| train-MinReturn         | -162         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.8         |
| train-StdReturn         | 32.7         |
------------------------------------------

 ---------------- Iteration 66 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 66           |
| ItrTime                 | 17           |
| LossAfter               | -0.15980114  |
| LossBefore              | -0.005499414 |
| Time                    | 1.14e+03     |
| Time-Optimization       | 0.241        |
| Time-SampleProc         | 0.029        |
| Time-Sampling           | 16.7         |
| n_timesteps             | 670000       |
| train-AverageDiscoun... | -58.1        |
| train-AverageReturn     | -92.2        |
| train-EnvExecTime       | 2.51         |
| train-MaxReturn         | -8.7         |
| train-MinReturn         | -186         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.9         |
| train-StdReturn         | 37.9         |
------------------------------------------

 ---------------- Iteration 67 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 67          |
| ItrTime                 | 17          |
| LossAfter               | -0.43183878 |
| LossBefore              | 0.0404334   |
| Time                    | 1.16e+03    |
| Time-Optimization       | 0.253       |
| Time-SampleProc         | 0.022       |
| Time-Sampling           | 16.7        |
| n_timesteps             | 680000      |
| train-AverageDiscoun... | -57.9       |
| train-AverageReturn     | -92.5       |
| train-EnvExecTime       | 2.57        |
| train-MaxReturn         | -2.26       |
| train-MinReturn         | -183        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 13.9        |
| train-StdReturn         | 40.8        |
-----------------------------------------

 ---------------- Iteration 68 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 68          |
| ItrTime                 | 17          |
| LossAfter               | -5.171535   |
| LossBefore              | 0.025065564 |
| Time                    | 1.18e+03    |
| Time-Optimization       | 0.247       |
| Time-SampleProc         | 0.026       |
| Time-Sampling           | 16.7        |
| n_timesteps             | 690000      |
| train-AverageDiscoun... | -57.6       |
| train-AverageReturn     | -91.4       |
| train-EnvExecTime       | 2.53        |
| train-MaxReturn         | 5.18        |
| train-MinReturn         | -174        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 13.9        |
| train-StdReturn         | 44          |
-----------------------------------------

 ---------------- Iteration 69 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 69          |
| ItrTime                 | 17.1        |
| LossAfter               | -6.4267735  |
| LossBefore              | 0.011678113 |
| Time                    | 1.2e+03     |
| Time-Optimization       | 0.241       |
| Time-SampleProc         | 0.022       |
| Time-Sampling           | 16.8        |
| n_timesteps             | 700000      |
| train-AverageDiscoun... | -42.1       |
| train-AverageReturn     | -65         |
| train-EnvExecTime       | 2.53        |
| train-MaxReturn         | 52.6        |
| train-MinReturn         | -213        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14          |
| train-StdReturn         | 50.1        |
-----------------------------------------

 ---------------- Iteration 70 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 70          |
| ItrTime                 | 17.1        |
| LossAfter               | -5.02565    |
| LossBefore              | 0.031696413 |
| Time                    | 1.21e+03    |
| Time-Optimization       | 0.249       |
| Time-SampleProc         | 0.026       |
| Time-Sampling           | 16.8        |
| n_timesteps             | 710000      |
| train-AverageDiscoun... | -30.1       |
| train-AverageReturn     | -43.1       |
| train-EnvExecTime       | 2.56        |
| train-MaxReturn         | 69.1        |
| train-MinReturn         | -160        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14          |
| train-StdReturn         | 34.8        |
-----------------------------------------

 ---------------- Iteration 71 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 71           |
| ItrTime                 | 17.3         |
| LossAfter               | -1.2701142   |
| LossBefore              | -0.007428314 |
| Time                    | 1.23e+03     |
| Time-Optimization       | 0.236        |
| Time-SampleProc         | 0.03         |
| Time-Sampling           | 17           |
| n_timesteps             | 720000       |
| train-AverageDiscoun... | -21.7        |
| train-AverageReturn     | -31.8        |
| train-EnvExecTime       | 2.53         |
| train-MaxReturn         | 87           |
| train-MinReturn         | -166         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 40.8         |
------------------------------------------

 ---------------- Iteration 72 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 72          |
| ItrTime                 | 16.8        |
| LossAfter               | -0.9732501  |
| LossBefore              | 0.014950298 |
| Time                    | 1.25e+03    |
| Time-Optimization       | 0.244       |
| Time-SampleProc         | 0.023       |
| Time-Sampling           | 16.5        |
| n_timesteps             | 730000      |
| train-AverageDiscoun... | -27.1       |
| train-AverageReturn     | -37.9       |
| train-EnvExecTime       | 2.55        |
| train-MaxReturn         | 73          |
| train-MinReturn         | -115        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 13.7        |
| train-StdReturn         | 40.3        |
-----------------------------------------

 ---------------- Iteration 73 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 73            |
| ItrTime                 | 17.1          |
| LossAfter               | -0.8737452    |
| LossBefore              | 0.00042890626 |
| Time                    | 1.26e+03      |
| Time-Optimization       | 0.24          |
| Time-SampleProc         | 0.025         |
| Time-Sampling           | 16.9          |
| n_timesteps             | 740000        |
| train-AverageDiscoun... | -16.8         |
| train-AverageReturn     | -22.4         |
| train-EnvExecTime       | 2.56          |
| train-MaxReturn         | 106           |
| train-MinReturn         | -122          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14            |
| train-StdReturn         | 39.7          |
-------------------------------------------

 ---------------- Iteration 74 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 74          |
| ItrTime                 | 16.9        |
| LossAfter               | -0.75170225 |
| LossBefore              | 0.019435083 |
| Time                    | 1.28e+03    |
| Time-Optimization       | 0.235       |
| Time-SampleProc         | 0.024       |
| Time-Sampling           | 16.6        |
| n_timesteps             | 750000      |
| train-AverageDiscoun... | -19.3       |
| train-AverageReturn     | -25.8       |
| train-EnvExecTime       | 2.55        |
| train-MaxReturn         | 70          |
| train-MinReturn         | -166        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 13.8        |
| train-StdReturn         | 41.2        |
-----------------------------------------

 ---------------- Iteration 75 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 75          |
| ItrTime                 | 17.3        |
| LossAfter               | -0.51599735 |
| LossBefore              | 0.01750503  |
| Time                    | 1.3e+03     |
| Time-Optimization       | 0.236       |
| Time-SampleProc         | 0.029       |
| Time-Sampling           | 17.1        |
| n_timesteps             | 760000      |
| train-AverageDiscoun... | -18.9       |
| train-AverageReturn     | -25.7       |
| train-EnvExecTime       | 2.57        |
| train-MaxReturn         | 75.5        |
| train-MinReturn         | -136        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.2        |
| train-StdReturn         | 32.5        |
-----------------------------------------

 ---------------- Iteration 76 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 76           |
| ItrTime                 | 17.1         |
| LossAfter               | -0.6881853   |
| LossBefore              | 0.0082397945 |
| Time                    | 1.32e+03     |
| Time-Optimization       | 0.245        |
| Time-SampleProc         | 0.027        |
| Time-Sampling           | 16.8         |
| n_timesteps             | 770000       |
| train-AverageDiscoun... | -17.6        |
| train-AverageReturn     | -24.7        |
| train-EnvExecTime       | 2.55         |
| train-MaxReturn         | 93.4         |
| train-MinReturn         | -171         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14           |
| train-StdReturn         | 42.8         |
------------------------------------------

 ---------------- Iteration 77 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 77          |
| ItrTime                 | 17.3        |
| LossAfter               | -1.3166674  |
| LossBefore              | 0.010654101 |
| Time                    | 1.33e+03    |
| Time-Optimization       | 0.239       |
| Time-SampleProc         | 0.022       |
| Time-Sampling           | 17          |
| n_timesteps             | 780000      |
| train-AverageDiscoun... | -11.8       |
| train-AverageReturn     | -15.6       |
| train-EnvExecTime       | 2.61        |
| train-MaxReturn         | 103         |
| train-MinReturn         | -96.3       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 37.9        |
-----------------------------------------

 ---------------- Iteration 78 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 78           |
| ItrTime                 | 17.4         |
| LossAfter               | -1.7959238   |
| LossBefore              | -0.018753832 |
| Time                    | 1.35e+03     |
| Time-Optimization       | 0.239        |
| Time-SampleProc         | 0.025        |
| Time-Sampling           | 17.1         |
| n_timesteps             | 790000       |
| train-AverageDiscoun... | -13.8        |
| train-AverageReturn     | -16.6        |
| train-EnvExecTime       | 2.64         |
| train-MaxReturn         | 110          |
| train-MinReturn         | -115         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 37.8         |
------------------------------------------

 ---------------- Iteration 79 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 79          |
| ItrTime                 | 17.4        |
| LossAfter               | -0.4522308  |
| LossBefore              | 0.017745484 |
| Time                    | 1.37e+03    |
| Time-Optimization       | 0.247       |
| Time-SampleProc         | 0.027       |
| Time-Sampling           | 17.1        |
| n_timesteps             | 800000      |
| train-AverageDiscoun... | -10.5       |
| train-AverageReturn     | -12.5       |
| train-EnvExecTime       | 2.62        |
| train-MaxReturn         | 110         |
| train-MinReturn         | -88.8       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.2        |
| train-StdReturn         | 34.9        |
-----------------------------------------

 ---------------- Iteration 80 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 80          |
| ItrTime                 | 17.3        |
| LossAfter               | -0.24940811 |
| LossBefore              | 0.027579987 |
| Time                    | 1.38e+03    |
| Time-Optimization       | 0.243       |
| Time-SampleProc         | 0.024       |
| Time-Sampling           | 17          |
| n_timesteps             | 810000      |
| train-AverageDiscoun... | -13.6       |
| train-AverageReturn     | -18         |
| train-EnvExecTime       | 2.55        |
| train-MaxReturn         | 70.7        |
| train-MinReturn         | -92.4       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.2        |
| train-StdReturn         | 25.3        |
-----------------------------------------

 ---------------- Iteration 81 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 81            |
| ItrTime                 | 16.5          |
| LossAfter               | -0.2934165    |
| LossBefore              | -0.0103702145 |
| Time                    | 1.4e+03       |
| Time-Optimization       | 0.234         |
| Time-SampleProc         | 0.027         |
| Time-Sampling           | 16.3          |
| n_timesteps             | 820000        |
| train-AverageDiscoun... | -15.5         |
| train-AverageReturn     | -21.4         |
| train-EnvExecTime       | 2.51          |
| train-MaxReturn         | 52.7          |
| train-MinReturn         | -107          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 13.5          |
| train-StdReturn         | 32.1          |
-------------------------------------------

 ---------------- Iteration 82 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 82            |
| ItrTime                 | 17            |
| LossAfter               | -0.25399914   |
| LossBefore              | -0.0058570565 |
| Time                    | 1.42e+03      |
| Time-Optimization       | 0.248         |
| Time-SampleProc         | 0.022         |
| Time-Sampling           | 16.7          |
| n_timesteps             | 830000        |
| train-AverageDiscoun... | -14.7         |
| train-AverageReturn     | -19.4         |
| train-EnvExecTime       | 2.56          |
| train-MaxReturn         | 73.6          |
| train-MinReturn         | -88.4         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 13.9          |
| train-StdReturn         | 31.3          |
-------------------------------------------

 ---------------- Iteration 83 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 83           |
| ItrTime                 | 17.2         |
| LossAfter               | -0.28245133  |
| LossBefore              | -0.009427173 |
| Time                    | 1.44e+03     |
| Time-Optimization       | 0.246        |
| Time-SampleProc         | 0.022        |
| Time-Sampling           | 16.9         |
| n_timesteps             | 840000       |
| train-AverageDiscoun... | -13.8        |
| train-AverageReturn     | -19.1        |
| train-EnvExecTime       | 2.53         |
| train-MaxReturn         | 88.3         |
| train-MinReturn         | -119         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 36           |
------------------------------------------

 ---------------- Iteration 84 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 84          |
| ItrTime                 | 17.5        |
| LossAfter               | -0.34119493 |
| LossBefore              | 0.014323901 |
| Time                    | 1.45e+03    |
| Time-Optimization       | 0.243       |
| Time-SampleProc         | 0.024       |
| Time-Sampling           | 17.3        |
| n_timesteps             | 850000      |
| train-AverageDiscoun... | -12.5       |
| train-AverageReturn     | -16         |
| train-EnvExecTime       | 2.7         |
| train-MaxReturn         | 94.3        |
| train-MinReturn         | -194        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.3        |
| train-StdReturn         | 43.4        |
-----------------------------------------

 ---------------- Iteration 85 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 85          |
| ItrTime                 | 16.7        |
| LossAfter               | -0.33811873 |
| LossBefore              | 0.019250061 |
| Time                    | 1.47e+03    |
| Time-Optimization       | 0.239       |
| Time-SampleProc         | 0.03        |
| Time-Sampling           | 16.5        |
| n_timesteps             | 860000      |
| train-AverageDiscoun... | -11.6       |
| train-AverageReturn     | -17         |
| train-EnvExecTime       | 2.61        |
| train-MaxReturn         | 67.1        |
| train-MinReturn         | -96.4       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 13.6        |
| train-StdReturn         | 37.9        |
-----------------------------------------

 ---------------- Iteration 86 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 86          |
| ItrTime                 | 17.3        |
| LossAfter               | -0.03027065 |
| LossBefore              | 0.012522241 |
| Time                    | 1.49e+03    |
| Time-Optimization       | 0.236       |
| Time-SampleProc         | 0.026       |
| Time-Sampling           | 17          |
| n_timesteps             | 870000      |
| train-AverageDiscoun... | -13.7       |
| train-AverageReturn     | -20.6       |
| train-EnvExecTime       | 2.58        |
| train-MaxReturn         | 51          |
| train-MinReturn         | -131        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.2        |
| train-StdReturn         | 33.9        |
-----------------------------------------

 ---------------- Iteration 87 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 87           |
| ItrTime                 | 17.4         |
| LossAfter               | -0.10702857  |
| LossBefore              | -0.018582812 |
| Time                    | 1.5e+03      |
| Time-Optimization       | 0.247        |
| Time-SampleProc         | 0.025        |
| Time-Sampling           | 17.1         |
| n_timesteps             | 880000       |
| train-AverageDiscoun... | -14          |
| train-AverageReturn     | -20.2        |
| train-EnvExecTime       | 2.63         |
| train-MaxReturn         | 79.1         |
| train-MinReturn         | -126         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 40           |
------------------------------------------

 ---------------- Iteration 88 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 88            |
| ItrTime                 | 16.9          |
| LossAfter               | -0.2218148    |
| LossBefore              | -0.0010300049 |
| Time                    | 1.52e+03      |
| Time-Optimization       | 0.241         |
| Time-SampleProc         | 0.021         |
| Time-Sampling           | 16.6          |
| n_timesteps             | 890000        |
| train-AverageDiscoun... | -12.4         |
| train-AverageReturn     | -17.9         |
| train-EnvExecTime       | 2.57          |
| train-MaxReturn         | 112           |
| train-MinReturn         | -108          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 13.8          |
| train-StdReturn         | 33.3          |
-------------------------------------------

 ---------------- Iteration 89 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 89           |
| ItrTime                 | 17.4         |
| LossAfter               | -0.37218407  |
| LossBefore              | -0.028663225 |
| Time                    | 1.54e+03     |
| Time-Optimization       | 0.236        |
| Time-SampleProc         | 0.025        |
| Time-Sampling           | 17.1         |
| n_timesteps             | 900000       |
| train-AverageDiscoun... | -14.1        |
| train-AverageReturn     | -18.8        |
| train-EnvExecTime       | 2.64         |
| train-MaxReturn         | 58.2         |
| train-MinReturn         | -98.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 31.4         |
------------------------------------------

 ---------------- Iteration 90 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 90           |
| ItrTime                 | 17.3         |
| LossAfter               | -1.1790918   |
| LossBefore              | -0.025196679 |
| Time                    | 1.56e+03     |
| Time-Optimization       | 0.239        |
| Time-SampleProc         | 0.03         |
| Time-Sampling           | 17           |
| n_timesteps             | 910000       |
| train-AverageDiscoun... | -12.1        |
| train-AverageReturn     | -18.1        |
| train-EnvExecTime       | 2.57         |
| train-MaxReturn         | 59.1         |
| train-MinReturn         | -131         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 36.5         |
------------------------------------------

 ---------------- Iteration 91 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 91          |
| ItrTime                 | 16.8        |
| LossAfter               | -0.18452902 |
| LossBefore              | 0.008223474 |
| Time                    | 1.57e+03    |
| Time-Optimization       | 0.236       |
| Time-SampleProc         | 0.022       |
| Time-Sampling           | 16.6        |
| n_timesteps             | 920000      |
| train-AverageDiscoun... | -10.4       |
| train-AverageReturn     | -15         |
| train-EnvExecTime       | 2.53        |
| train-MaxReturn         | 84          |
| train-MinReturn         | -108        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 13.8        |
| train-StdReturn         | 35.8        |
-----------------------------------------

 ---------------- Iteration 92 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 92           |
| ItrTime                 | 17.1         |
| LossAfter               | -0.27445394  |
| LossBefore              | -0.007718007 |
| Time                    | 1.59e+03     |
| Time-Optimization       | 0.24         |
| Time-SampleProc         | 0.025        |
| Time-Sampling           | 16.8         |
| n_timesteps             | 930000       |
| train-AverageDiscoun... | -4.56        |
| train-AverageReturn     | -4.97        |
| train-EnvExecTime       | 2.62         |
| train-MaxReturn         | 109          |
| train-MinReturn         | -164         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.9         |
| train-StdReturn         | 42.6         |
------------------------------------------

 ---------------- Iteration 93 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 93           |
| ItrTime                 | 17.4         |
| LossAfter               | -1.0755639   |
| LossBefore              | -0.030009754 |
| Time                    | 1.61e+03     |
| Time-Optimization       | 0.243        |
| Time-SampleProc         | 0.023        |
| Time-Sampling           | 17.1         |
| n_timesteps             | 940000       |
| train-AverageDiscoun... | -10.8        |
| train-AverageReturn     | -15.9        |
| train-EnvExecTime       | 2.57         |
| train-MaxReturn         | 108          |
| train-MinReturn         | -128         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 37           |
------------------------------------------

 ---------------- Iteration 94 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 94           |
| ItrTime                 | 16.7         |
| LossAfter               | -1.1597898   |
| LossBefore              | 0.0052532423 |
| Time                    | 1.62e+03     |
| Time-Optimization       | 0.24         |
| Time-SampleProc         | 0.029        |
| Time-Sampling           | 16.4         |
| n_timesteps             | 950000       |
| train-AverageDiscoun... | -8.33        |
| train-AverageReturn     | -12.5        |
| train-EnvExecTime       | 2.58         |
| train-MaxReturn         | 149          |
| train-MinReturn         | -179         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.6         |
| train-StdReturn         | 47.1         |
------------------------------------------

 ---------------- Iteration 95 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 95            |
| ItrTime                 | 16.8          |
| LossAfter               | -0.4661508    |
| LossBefore              | -0.0008970947 |
| Time                    | 1.64e+03      |
| Time-Optimization       | 0.246         |
| Time-SampleProc         | 0.027         |
| Time-Sampling           | 16.6          |
| n_timesteps             | 960000        |
| train-AverageDiscoun... | -14.7         |
| train-AverageReturn     | -20.9         |
| train-EnvExecTime       | 2.53          |
| train-MaxReturn         | 96.4          |
| train-MinReturn         | -136          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 13.8          |
| train-StdReturn         | 42.2          |
-------------------------------------------

 ---------------- Iteration 96 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 96          |
| ItrTime                 | 17.4        |
| LossAfter               | -0.7074842  |
| LossBefore              | 0.015970556 |
| Time                    | 1.66e+03    |
| Time-Optimization       | 0.242       |
| Time-SampleProc         | 0.024       |
| Time-Sampling           | 17.1        |
| n_timesteps             | 970000      |
| train-AverageDiscoun... | -22.1       |
| train-AverageReturn     | -32         |
| train-EnvExecTime       | 2.63        |
| train-MaxReturn         | 72.8        |
| train-MinReturn         | -154        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.2        |
| train-StdReturn         | 39.3        |
-----------------------------------------

 ---------------- Iteration 97 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 97           |
| ItrTime                 | 17           |
| LossAfter               | -0.79857415  |
| LossBefore              | -0.002341359 |
| Time                    | 1.68e+03     |
| Time-Optimization       | 0.253        |
| Time-SampleProc         | 0.029        |
| Time-Sampling           | 16.8         |
| n_timesteps             | 980000       |
| train-AverageDiscoun... | -22.8        |
| train-AverageReturn     | -33.3        |
| train-EnvExecTime       | 2.59         |
| train-MaxReturn         | 60.2         |
| train-MinReturn         | -112         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.9         |
| train-StdReturn         | 37.3         |
------------------------------------------

 ---------------- Iteration 98 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 98           |
| ItrTime                 | 17.4         |
| LossAfter               | -0.8460692   |
| LossBefore              | -0.009832249 |
| Time                    | 1.69e+03     |
| Time-Optimization       | 0.254        |
| Time-SampleProc         | 0.026        |
| Time-Sampling           | 17.1         |
| n_timesteps             | 990000       |
| train-AverageDiscoun... | -26.9        |
| train-AverageReturn     | -38.8        |
| train-EnvExecTime       | 2.63         |
| train-MaxReturn         | 62.3         |
| train-MinReturn         | -133         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 38.7         |
------------------------------------------

 ---------------- Iteration 99 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 99           |
| ItrTime                 | 17.4         |
| LossAfter               | -1.1775107   |
| LossBefore              | -0.010833472 |
| Time                    | 1.71e+03     |
| Time-Optimization       | 0.24         |
| Time-SampleProc         | 0.025        |
| Time-Sampling           | 17.1         |
| n_timesteps             | 1000000      |
| train-AverageDiscoun... | -19.6        |
| train-AverageReturn     | -26.9        |
| train-EnvExecTime       | 2.62         |
| train-MaxReturn         | 79.1         |
| train-MinReturn         | -110         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 41.1         |
------------------------------------------

 ---------------- Iteration 100 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 100          |
| ItrTime                 | 17.1         |
| LossAfter               | -1.6462072   |
| LossBefore              | -0.015134864 |
| Time                    | 1.73e+03     |
| Time-Optimization       | 0.237        |
| Time-SampleProc         | 0.024        |
| Time-Sampling           | 16.8         |
| n_timesteps             | 1010000      |
| train-AverageDiscoun... | -29.6        |
| train-AverageReturn     | -43.8        |
| train-EnvExecTime       | 2.63         |
| train-MaxReturn         | 69.1         |
| train-MinReturn         | -157         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.9         |
| train-StdReturn         | 37.8         |
------------------------------------------

 ---------------- Iteration 101 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 101         |
| ItrTime                 | 17.3        |
| LossAfter               | -2.425321   |
| LossBefore              | -0.01109715 |
| Time                    | 1.74e+03    |
| Time-Optimization       | 0.239       |
| Time-SampleProc         | 0.024       |
| Time-Sampling           | 17          |
| n_timesteps             | 1020000     |
| train-AverageDiscoun... | -32.3       |
| train-AverageReturn     | -48.7       |
| train-EnvExecTime       | 2.63        |
| train-MaxReturn         | 69.9        |
| train-MinReturn         | -129        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 38.8        |
-----------------------------------------

 ---------------- Iteration 102 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 102          |
| ItrTime                 | 17.4         |
| LossAfter               | -3.807072    |
| LossBefore              | -0.015046585 |
| Time                    | 1.76e+03     |
| Time-Optimization       | 0.238        |
| Time-SampleProc         | 0.025        |
| Time-Sampling           | 17.1         |
| n_timesteps             | 1030000      |
| train-AverageDiscoun... | -35.4        |
| train-AverageReturn     | -54          |
| train-EnvExecTime       | 2.68         |
| train-MaxReturn         | 39.5         |
| train-MinReturn         | -119         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 33.9         |
------------------------------------------

 ---------------- Iteration 103 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 103          |
| ItrTime                 | 17.3         |
| LossAfter               | -2.1018672   |
| LossBefore              | 0.0011540649 |
| Time                    | 1.78e+03     |
| Time-Optimization       | 0.243        |
| Time-SampleProc         | 0.022        |
| Time-Sampling           | 17.1         |
| n_timesteps             | 1040000      |
| train-AverageDiscoun... | -34.5        |
| train-AverageReturn     | -53.6        |
| train-EnvExecTime       | 2.69         |
| train-MaxReturn         | 28.9         |
| train-MinReturn         | -95.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 23.8         |
------------------------------------------

 ---------------- Iteration 104 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 104          |
| ItrTime                 | 17.5         |
| LossAfter               | -9.93491     |
| LossBefore              | -0.006422058 |
| Time                    | 1.8e+03      |
| Time-Optimization       | 0.237        |
| Time-SampleProc         | 0.029        |
| Time-Sampling           | 17.2         |
| n_timesteps             | 1050000      |
| train-AverageDiscoun... | -39          |
| train-AverageReturn     | -60.4        |
| train-EnvExecTime       | 2.73         |
| train-MaxReturn         | 21.3         |
| train-MinReturn         | -89.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 13.9         |
------------------------------------------

 ---------------- Iteration 105 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 105          |
| ItrTime                 | 17.3         |
| LossAfter               | -35.528      |
| LossBefore              | 0.0014649048 |
| Time                    | 1.81e+03     |
| Time-Optimization       | 0.237        |
| Time-SampleProc         | 0.021        |
| Time-Sampling           | 17.1         |
| n_timesteps             | 1060000      |
| train-AverageDiscoun... | -40.3        |
| train-AverageReturn     | -62.3        |
| train-EnvExecTime       | 2.72         |
| train-MaxReturn         | -4.18        |
| train-MinReturn         | -88          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 8.18         |
------------------------------------------

 ---------------- Iteration 106 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
----------------------------------------
| Itr                     | 106        |
| ItrTime                 | 17.5       |
| LossAfter               | -28.660557 |
| LossBefore              | 0.02642851 |
| Time                    | 1.83e+03   |
| Time-Optimization       | 0.244      |
| Time-SampleProc         | 0.023      |
| Time-Sampling           | 17.2       |
| n_timesteps             | 1070000    |
| train-AverageDiscoun... | -39.7      |
| train-AverageReturn     | -61.8      |
| train-EnvExecTime       | 2.69       |
| train-MaxReturn         | -59.6      |
| train-MinReturn         | -77.2      |
| train-NumTrajs          | 100        |
| train-PolicyExecTime    | 14.2       |
| train-StdReturn         | 1.93       |
----------------------------------------

 ---------------- Iteration 107 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 107          |
| ItrTime                 | 17.4         |
| LossAfter               | -0.059890553 |
| LossBefore              | 0.02110662   |
| Time                    | 1.85e+03     |
| Time-Optimization       | 0.238        |
| Time-SampleProc         | 0.031        |
| Time-Sampling           | 17.1         |
| n_timesteps             | 1080000      |
| train-AverageDiscoun... | -39.5        |
| train-AverageReturn     | -61.6        |
| train-EnvExecTime       | 2.73         |
| train-MaxReturn         | -57.7        |
| train-MinReturn         | -65.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 1.47         |
------------------------------------------

 ---------------- Iteration 108 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 108         |
| ItrTime                 | 17.5        |
| LossAfter               | 0.009426153 |
| LossBefore              | 0.00231578  |
| Time                    | 1.87e+03    |
| Time-Optimization       | 0.252       |
| Time-SampleProc         | 0.027       |
| Time-Sampling           | 17.2        |
| n_timesteps             | 1090000     |
| train-AverageDiscoun... | -39.4       |
| train-AverageReturn     | -61.4       |
| train-EnvExecTime       | 2.76        |
| train-MaxReturn         | -58.3       |
| train-MinReturn         | -64.3       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.2        |
| train-StdReturn         | 1.18        |
-----------------------------------------

 ---------------- Iteration 109 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 109         |
| ItrTime                 | 16.8        |
| LossAfter               | -0.10755848 |
| LossBefore              | -0.03010552 |
| Time                    | 1.88e+03    |
| Time-Optimization       | 0.237       |
| Time-SampleProc         | 0.026       |
| Time-Sampling           | 16.5        |
| n_timesteps             | 1100000     |
| train-AverageDiscoun... | -39.3       |
| train-AverageReturn     | -61.4       |
| train-EnvExecTime       | 2.66        |
| train-MaxReturn         | -58.4       |
| train-MinReturn         | -64.1       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 13.6        |
| train-StdReturn         | 0.95        |
-----------------------------------------

 ---------------- Iteration 110 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 110          |
| ItrTime                 | 17           |
| LossAfter               | -0.061744396 |
| LossBefore              | 0.0128026735 |
| Time                    | 1.9e+03      |
| Time-Optimization       | 0.237        |
| Time-SampleProc         | 0.024        |
| Time-Sampling           | 16.7         |
| n_timesteps             | 1110000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.74         |
| train-MaxReturn         | -57.9        |
| train-MinReturn         | -64.9        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.7         |
| train-StdReturn         | 1.23         |
------------------------------------------

 ---------------- Iteration 111 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 111          |
| ItrTime                 | 17.3         |
| LossAfter               | -0.07985119  |
| LossBefore              | -0.026302056 |
| Time                    | 1.92e+03     |
| Time-Optimization       | 0.246        |
| Time-SampleProc         | 0.028        |
| Time-Sampling           | 17           |
| n_timesteps             | 1120000      |
| train-AverageDiscoun... | -39.2        |
| train-AverageReturn     | -61.2        |
| train-EnvExecTime       | 2.67         |
| train-MaxReturn         | -58.2        |
| train-MinReturn         | -64.1        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 1.17         |
------------------------------------------

 ---------------- Iteration 112 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 112          |
| ItrTime                 | 17.1         |
| LossAfter               | -0.048615355 |
| LossBefore              | -0.016704101 |
| Time                    | 1.93e+03     |
| Time-Optimization       | 0.24         |
| Time-SampleProc         | 0.029        |
| Time-Sampling           | 16.8         |
| n_timesteps             | 1130000      |
| train-AverageDiscoun... | -39.3        |
| train-AverageReturn     | -61.3        |
| train-EnvExecTime       | 2.7          |
| train-MaxReturn         | -58.8        |
| train-MinReturn         | -64.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.8         |
| train-StdReturn         | 0.963        |
------------------------------------------

 ---------------- Iteration 113 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 113          |
| ItrTime                 | 17.3         |
| LossAfter               | -0.036896262 |
| LossBefore              | -0.03472707  |
| Time                    | 1.95e+03     |
| Time-Optimization       | 0.234        |
| Time-SampleProc         | 0.024        |
| Time-Sampling           | 17.1         |
| n_timesteps             | 1140000      |
| train-AverageDiscoun... | -39.2        |
| train-AverageReturn     | -61.3        |
| train-EnvExecTime       | 2.71         |
| train-MaxReturn         | -57.6        |
| train-MinReturn         | -64.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 1.21         |
------------------------------------------

 ---------------- Iteration 114 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 114         |
| ItrTime                 | 17.3        |
| LossAfter               | 0.009960072 |
| LossBefore              | 0.012038069 |
| Time                    | 1.97e+03    |
| Time-Optimization       | 0.241       |
| Time-SampleProc         | 0.029       |
| Time-Sampling           | 17          |
| n_timesteps             | 1150000     |
| train-AverageDiscoun... | -39.2       |
| train-AverageReturn     | -61.3       |
| train-EnvExecTime       | 2.7         |
| train-MaxReturn         | -57         |
| train-MinReturn         | -64.6       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14          |
| train-StdReturn         | 1.17        |
-----------------------------------------

 ---------------- Iteration 115 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 115          |
| ItrTime                 | 16.9         |
| LossAfter               | -0.008574707 |
| LossBefore              | 0.0068780393 |
| Time                    | 1.99e+03     |
| Time-Optimization       | 0.234        |
| Time-SampleProc         | 0.028        |
| Time-Sampling           | 16.6         |
| n_timesteps             | 1160000      |
| train-AverageDiscoun... | -39.6        |
| train-AverageReturn     | -61.6        |
| train-EnvExecTime       | 2.69         |
| train-MaxReturn         | -58.9        |
| train-MinReturn         | -64.1        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.6         |
| train-StdReturn         | 1.08         |
------------------------------------------

 ---------------- Iteration 116 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 116          |
| ItrTime                 | 17.1         |
| LossAfter               | -0.012850055 |
| LossBefore              | 0.014829132  |
| Time                    | 2e+03        |
| Time-Optimization       | 0.243        |
| Time-SampleProc         | 0.021        |
| Time-Sampling           | 16.9         |
| n_timesteps             | 1170000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.72         |
| train-MaxReturn         | -59.1        |
| train-MinReturn         | -64.4        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.9         |
| train-StdReturn         | 1.09         |
------------------------------------------

 ---------------- Iteration 117 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 117          |
| ItrTime                 | 17.2         |
| LossAfter               | -0.049041852 |
| LossBefore              | -0.00942208  |
| Time                    | 2.02e+03     |
| Time-Optimization       | 0.247        |
| Time-SampleProc         | 0.023        |
| Time-Sampling           | 16.9         |
| n_timesteps             | 1180000      |
| train-AverageDiscoun... | -39.6        |
| train-AverageReturn     | -61.6        |
| train-EnvExecTime       | 2.69         |
| train-MaxReturn         | -59.4        |
| train-MinReturn         | -64.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.9         |
| train-StdReturn         | 1.14         |
------------------------------------------

 ---------------- Iteration 118 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 118          |
| ItrTime                 | 17.1         |
| LossAfter               | -0.06904465  |
| LossBefore              | 0.0009407791 |
| Time                    | 2.04e+03     |
| Time-Optimization       | 0.242        |
| Time-SampleProc         | 0.026        |
| Time-Sampling           | 16.8         |
| n_timesteps             | 1190000      |
| train-AverageDiscoun... | -39.3        |
| train-AverageReturn     | -61.3        |
| train-EnvExecTime       | 2.7          |
| train-MaxReturn         | -57.8        |
| train-MinReturn         | -64          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.8         |
| train-StdReturn         | 1.14         |
------------------------------------------

 ---------------- Iteration 119 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 119          |
| ItrTime                 | 17.4         |
| LossAfter               | -0.075157434 |
| LossBefore              | -0.033658653 |
| Time                    | 2.06e+03     |
| Time-Optimization       | 0.239        |
| Time-SampleProc         | 0.027        |
| Time-Sampling           | 17.1         |
| n_timesteps             | 1200000      |
| train-AverageDiscoun... | -39.5        |
| train-AverageReturn     | -61.6        |
| train-EnvExecTime       | 2.67         |
| train-MaxReturn         | -58.2        |
| train-MinReturn         | -65          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 1.12         |
------------------------------------------

 ---------------- Iteration 120 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 120          |
| ItrTime                 | 17.5         |
| LossAfter               | -0.06998512  |
| LossBefore              | -0.004997464 |
| Time                    | 2.07e+03     |
| Time-Optimization       | 0.245        |
| Time-SampleProc         | 0.03         |
| Time-Sampling           | 17.2         |
| n_timesteps             | 1210000      |
| train-AverageDiscoun... | -39.5        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.73         |
| train-MaxReturn         | -58.5        |
| train-MinReturn         | -65          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 1.25         |
------------------------------------------

 ---------------- Iteration 121 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 121          |
| ItrTime                 | 17.6         |
| LossAfter               | -0.05325067  |
| LossBefore              | -0.011702076 |
| Time                    | 2.09e+03     |
| Time-Optimization       | 0.259        |
| Time-SampleProc         | 0.027        |
| Time-Sampling           | 17.3         |
| n_timesteps             | 1220000      |
| train-AverageDiscoun... | -39.3        |
| train-AverageReturn     | -61.4        |
| train-EnvExecTime       | 2.73         |
| train-MaxReturn         | -57.5        |
| train-MinReturn         | -64.4        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.3         |
| train-StdReturn         | 1.15         |
------------------------------------------

 ---------------- Iteration 122 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 122            |
| ItrTime                 | 16.9           |
| LossAfter               | -0.018853065   |
| LossBefore              | -0.00066961977 |
| Time                    | 2.11e+03       |
| Time-Optimization       | 0.257          |
| Time-SampleProc         | 0.022          |
| Time-Sampling           | 16.7           |
| n_timesteps             | 1230000        |
| train-AverageDiscoun... | -39.5          |
| train-AverageReturn     | -61.6          |
| train-EnvExecTime       | 2.62           |
| train-MaxReturn         | -58.6          |
| train-MinReturn         | -65.4          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 13.8           |
| train-StdReturn         | 1.15           |
--------------------------------------------

 ---------------- Iteration 123 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 123          |
| ItrTime                 | 17.3         |
| LossAfter               | -0.0417758   |
| LossBefore              | -0.027379932 |
| Time                    | 2.12e+03     |
| Time-Optimization       | 0.251        |
| Time-SampleProc         | 0.023        |
| Time-Sampling           | 17           |
| n_timesteps             | 1240000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.4        |
| train-EnvExecTime       | 2.69         |
| train-MaxReturn         | -58.7        |
| train-MinReturn         | -64.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 1.13         |
------------------------------------------

 ---------------- Iteration 124 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 124         |
| ItrTime                 | 17.1        |
| LossAfter               | -0.0234833  |
| LossBefore              | 0.017252404 |
| Time                    | 2.14e+03    |
| Time-Optimization       | 0.247       |
| Time-SampleProc         | 0.03        |
| Time-Sampling           | 16.8        |
| n_timesteps             | 1250000     |
| train-AverageDiscoun... | -39.3       |
| train-AverageReturn     | -61.4       |
| train-EnvExecTime       | 2.68        |
| train-MaxReturn         | -58.6       |
| train-MinReturn         | -64.8       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 13.9        |
| train-StdReturn         | 1.17        |
-----------------------------------------

 ---------------- Iteration 125 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 125           |
| ItrTime                 | 17.5          |
| LossAfter               | -0.028365003  |
| LossBefore              | -0.0010150513 |
| Time                    | 2.16e+03      |
| Time-Optimization       | 0.247         |
| Time-SampleProc         | 0.029         |
| Time-Sampling           | 17.2          |
| n_timesteps             | 1260000       |
| train-AverageDiscoun... | -39.5         |
| train-AverageReturn     | -61.5         |
| train-EnvExecTime       | 2.79          |
| train-MaxReturn         | -58.8         |
| train-MinReturn         | -64.6         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 1.22          |
-------------------------------------------

 ---------------- Iteration 126 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 126          |
| ItrTime                 | 16.8         |
| LossAfter               | -0.03604275  |
| LossBefore              | -0.005638887 |
| Time                    | 2.18e+03     |
| Time-Optimization       | 0.254        |
| Time-SampleProc         | 0.021        |
| Time-Sampling           | 16.6         |
| n_timesteps             | 1270000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.4        |
| train-EnvExecTime       | 2.68         |
| train-MaxReturn         | -58.7        |
| train-MinReturn         | -64.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.6         |
| train-StdReturn         | 1.09         |
------------------------------------------

 ---------------- Iteration 127 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 127           |
| ItrTime                 | 17.2          |
| LossAfter               | -0.027064547  |
| LossBefore              | -0.0071430434 |
| Time                    | 2.19e+03      |
| Time-Optimization       | 0.259         |
| Time-SampleProc         | 0.021         |
| Time-Sampling           | 16.9          |
| n_timesteps             | 1280000       |
| train-AverageDiscoun... | -39.5         |
| train-AverageReturn     | -61.5         |
| train-EnvExecTime       | 2.7           |
| train-MaxReturn         | -58.1         |
| train-MinReturn         | -64.3         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 13.9          |
| train-StdReturn         | 1.17          |
-------------------------------------------

 ---------------- Iteration 128 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 128           |
| ItrTime                 | 17.5          |
| LossAfter               | -0.0028853484 |
| LossBefore              | 0.01577417    |
| Time                    | 2.21e+03      |
| Time-Optimization       | 0.251         |
| Time-SampleProc         | 0.028         |
| Time-Sampling           | 17.3          |
| n_timesteps             | 1290000       |
| train-AverageDiscoun... | -39.4         |
| train-AverageReturn     | -61.5         |
| train-EnvExecTime       | 2.72          |
| train-MaxReturn         | -58.5         |
| train-MinReturn         | -64.3         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.3          |
| train-StdReturn         | 1.18          |
-------------------------------------------

 ---------------- Iteration 129 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 129          |
| ItrTime                 | 17.3         |
| LossAfter               | -0.040985778 |
| LossBefore              | -0.015285468 |
| Time                    | 2.23e+03     |
| Time-Optimization       | 0.264        |
| Time-SampleProc         | 0.023        |
| Time-Sampling           | 17           |
| n_timesteps             | 1300000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.4        |
| train-EnvExecTime       | 2.71         |
| train-MaxReturn         | -58.1        |
| train-MinReturn         | -64.3        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14           |
| train-StdReturn         | 1.1          |
------------------------------------------

 ---------------- Iteration 130 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 130          |
| ItrTime                 | 17.4         |
| LossAfter               | -0.043359116 |
| LossBefore              | -0.026130065 |
| Time                    | 2.25e+03     |
| Time-Optimization       | 0.256        |
| Time-SampleProc         | 0.021        |
| Time-Sampling           | 17.1         |
| n_timesteps             | 1310000      |
| train-AverageDiscoun... | -39.5        |
| train-AverageReturn     | -61.6        |
| train-EnvExecTime       | 2.71         |
| train-MaxReturn         | -56.8        |
| train-MinReturn         | -64.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 1.24         |
------------------------------------------

 ---------------- Iteration 131 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 131          |
| ItrTime                 | 17.4         |
| LossAfter               | -0.03621524  |
| LossBefore              | -0.015431882 |
| Time                    | 2.26e+03     |
| Time-Optimization       | 0.259        |
| Time-SampleProc         | 0.022        |
| Time-Sampling           | 17.1         |
| n_timesteps             | 1320000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.69         |
| train-MaxReturn         | -59.1        |
| train-MinReturn         | -64.9        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 1.15         |
------------------------------------------

 ---------------- Iteration 132 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 132            |
| ItrTime                 | 17.4           |
| LossAfter               | -0.02853721    |
| LossBefore              | -0.00017963257 |
| Time                    | 2.28e+03       |
| Time-Optimization       | 0.27           |
| Time-SampleProc         | 0.023          |
| Time-Sampling           | 17.1           |
| n_timesteps             | 1330000        |
| train-AverageDiscoun... | -39.3          |
| train-AverageReturn     | -61.3          |
| train-EnvExecTime       | 2.7            |
| train-MaxReturn         | -58.2          |
| train-MinReturn         | -64.3          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 14.2           |
| train-StdReturn         | 1.07           |
--------------------------------------------

 ---------------- Iteration 133 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 133          |
| ItrTime                 | 17.3         |
| LossAfter               | -0.015688952 |
| LossBefore              | 0.0022710967 |
| Time                    | 2.3e+03      |
| Time-Optimization       | 0.261        |
| Time-SampleProc         | 0.021        |
| Time-Sampling           | 17           |
| n_timesteps             | 1340000      |
| train-AverageDiscoun... | -39.3        |
| train-AverageReturn     | -61.4        |
| train-EnvExecTime       | 2.73         |
| train-MaxReturn         | -59.2        |
| train-MinReturn         | -63.7        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14           |
| train-StdReturn         | 0.88         |
------------------------------------------

 ---------------- Iteration 134 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 134           |
| ItrTime                 | 17.4          |
| LossAfter               | -0.0050484193 |
| LossBefore              | -0.0037733384 |
| Time                    | 2.32e+03      |
| Time-Optimization       | 0.266         |
| Time-SampleProc         | 0.026         |
| Time-Sampling           | 17.1          |
| n_timesteps             | 1350000       |
| train-AverageDiscoun... | -39.4         |
| train-AverageReturn     | -61.5         |
| train-EnvExecTime       | 2.73          |
| train-MaxReturn         | -58.3         |
| train-MinReturn         | -64.2         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14            |
| train-StdReturn         | 1.04          |
-------------------------------------------

 ---------------- Iteration 135 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 135          |
| ItrTime                 | 17           |
| LossAfter               | -0.03525601  |
| LossBefore              | -0.016213337 |
| Time                    | 2.33e+03     |
| Time-Optimization       | 0.251        |
| Time-SampleProc         | 0.028        |
| Time-Sampling           | 16.7         |
| n_timesteps             | 1360000      |
| train-AverageDiscoun... | -39.5        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.74         |
| train-MaxReturn         | -58.8        |
| train-MinReturn         | -65.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.7         |
| train-StdReturn         | 1.11         |
------------------------------------------

 ---------------- Iteration 136 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 136          |
| ItrTime                 | 17.2         |
| LossAfter               | -0.027405249 |
| LossBefore              | -0.009324446 |
| Time                    | 2.35e+03     |
| Time-Optimization       | 0.258        |
| Time-SampleProc         | 0.023        |
| Time-Sampling           | 16.9         |
| n_timesteps             | 1370000      |
| train-AverageDiscoun... | -39.2        |
| train-AverageReturn     | -61.3        |
| train-EnvExecTime       | 2.67         |
| train-MaxReturn         | -58.2        |
| train-MinReturn         | -65.9        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.9         |
| train-StdReturn         | 1.17         |
------------------------------------------

 ---------------- Iteration 137 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 137         |
| ItrTime                 | 16.9        |
| LossAfter               | 0.019864874 |
| LossBefore              | 0.03376482  |
| Time                    | 2.37e+03    |
| Time-Optimization       | 0.254       |
| Time-SampleProc         | 0.024       |
| Time-Sampling           | 16.6        |
| n_timesteps             | 1380000     |
| train-AverageDiscoun... | -39.5       |
| train-AverageReturn     | -61.5       |
| train-EnvExecTime       | 2.69        |
| train-MaxReturn         | -58         |
| train-MinReturn         | -65.7       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 13.7        |
| train-StdReturn         | 1.26        |
-----------------------------------------

 ---------------- Iteration 138 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 138          |
| ItrTime                 | 16.9         |
| LossAfter               | -0.051135547 |
| LossBefore              | -0.014923956 |
| Time                    | 2.38e+03     |
| Time-Optimization       | 0.26         |
| Time-SampleProc         | 0.03         |
| Time-Sampling           | 16.6         |
| n_timesteps             | 1390000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.67         |
| train-MaxReturn         | -57.7        |
| train-MinReturn         | -64.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.7         |
| train-StdReturn         | 1.19         |
------------------------------------------

 ---------------- Iteration 139 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 139          |
| ItrTime                 | 17.1         |
| LossAfter               | -0.044852626 |
| LossBefore              | -0.021807438 |
| Time                    | 2.4e+03      |
| Time-Optimization       | 0.261        |
| Time-SampleProc         | 0.021        |
| Time-Sampling           | 16.8         |
| n_timesteps             | 1400000      |
| train-AverageDiscoun... | -39.3        |
| train-AverageReturn     | -61.3        |
| train-EnvExecTime       | 2.7          |
| train-MaxReturn         | -59.3        |
| train-MinReturn         | -64.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.8         |
| train-StdReturn         | 0.966        |
------------------------------------------

 ---------------- Iteration 140 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 140          |
| ItrTime                 | 16.9         |
| LossAfter               | -0.05841688  |
| LossBefore              | -0.033278897 |
| Time                    | 2.42e+03     |
| Time-Optimization       | 0.258        |
| Time-SampleProc         | 0.028        |
| Time-Sampling           | 16.6         |
| n_timesteps             | 1410000      |
| train-AverageDiscoun... | -39.3        |
| train-AverageReturn     | -61.4        |
| train-EnvExecTime       | 2.71         |
| train-MaxReturn         | -58.1        |
| train-MinReturn         | -64.1        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.6         |
| train-StdReturn         | 1.25         |
------------------------------------------

 ---------------- Iteration 141 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 141          |
| ItrTime                 | 17           |
| LossAfter               | -0.011133786 |
| LossBefore              | 0.0019073089 |
| Time                    | 2.43e+03     |
| Time-Optimization       | 0.256        |
| Time-SampleProc         | 0.033        |
| Time-Sampling           | 16.7         |
| n_timesteps             | 1420000      |
| train-AverageDiscoun... | -39.5        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.67         |
| train-MaxReturn         | -59          |
| train-MinReturn         | -63.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.8         |
| train-StdReturn         | 1.02         |
------------------------------------------

 ---------------- Iteration 142 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 142           |
| ItrTime                 | 17.1          |
| LossAfter               | -0.0020220305 |
| LossBefore              | 0.0053383126  |
| Time                    | 2.45e+03      |
| Time-Optimization       | 0.256         |
| Time-SampleProc         | 0.029         |
| Time-Sampling           | 16.8          |
| n_timesteps             | 1430000       |
| train-AverageDiscoun... | -39.4         |
| train-AverageReturn     | -61.5         |
| train-EnvExecTime       | 2.68          |
| train-MaxReturn         | -59.2         |
| train-MinReturn         | -65.2         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 13.9          |
| train-StdReturn         | 1.24          |
-------------------------------------------

 ---------------- Iteration 143 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 143          |
| ItrTime                 | 17.4         |
| LossAfter               | -0.031040914 |
| LossBefore              | -0.012338043 |
| Time                    | 2.47e+03     |
| Time-Optimization       | 0.255        |
| Time-SampleProc         | 0.028        |
| Time-Sampling           | 17.1         |
| n_timesteps             | 1440000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.4        |
| train-EnvExecTime       | 2.73         |
| train-MaxReturn         | -58.4        |
| train-MinReturn         | -65.7        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 1.23         |
------------------------------------------

 ---------------- Iteration 144 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 144          |
| ItrTime                 | 17.5         |
| LossAfter               | -0.013093213 |
| LossBefore              | 0.0052464874 |
| Time                    | 2.49e+03     |
| Time-Optimization       | 0.275        |
| Time-SampleProc         | 0.03         |
| Time-Sampling           | 17.2         |
| n_timesteps             | 1450000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.75         |
| train-MaxReturn         | -59.2        |
| train-MinReturn         | -64.3        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 1.06         |
------------------------------------------

 ---------------- Iteration 145 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 145           |
| ItrTime                 | 17.4          |
| LossAfter               | -0.0026058105 |
| LossBefore              | 0.005523413   |
| Time                    | 2.5e+03       |
| Time-Optimization       | 0.259         |
| Time-SampleProc         | 0.021         |
| Time-Sampling           | 17.2          |
| n_timesteps             | 1460000       |
| train-AverageDiscoun... | -39.5         |
| train-AverageReturn     | -61.6         |
| train-EnvExecTime       | 2.71          |
| train-MaxReturn         | -59.1         |
| train-MinReturn         | -64.6         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.2          |
| train-StdReturn         | 1.05          |
-------------------------------------------

 ---------------- Iteration 146 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 146          |
| ItrTime                 | 17.4         |
| LossAfter               | -0.020399408 |
| LossBefore              | 0.008446839  |
| Time                    | 2.52e+03     |
| Time-Optimization       | 0.25         |
| Time-SampleProc         | 0.027        |
| Time-Sampling           | 17.1         |
| n_timesteps             | 1470000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.4        |
| train-EnvExecTime       | 2.73         |
| train-MaxReturn         | -58.3        |
| train-MinReturn         | -64.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 1.11         |
------------------------------------------

 ---------------- Iteration 147 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 147          |
| ItrTime                 | 17.2         |
| LossAfter               | -0.027210088 |
| LossBefore              | 0.0024172608 |
| Time                    | 2.54e+03     |
| Time-Optimization       | 0.259        |
| Time-SampleProc         | 0.023        |
| Time-Sampling           | 17           |
| n_timesteps             | 1480000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.74         |
| train-MaxReturn         | -58.4        |
| train-MinReturn         | -64.5        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.9         |
| train-StdReturn         | 1.28         |
------------------------------------------

 ---------------- Iteration 148 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 148          |
| ItrTime                 | 17.1         |
| LossAfter               | -0.03308596  |
| LossBefore              | 0.0071983337 |
| Time                    | 2.56e+03     |
| Time-Optimization       | 0.26         |
| Time-SampleProc         | 0.022        |
| Time-Sampling           | 16.8         |
| n_timesteps             | 1490000      |
| train-AverageDiscoun... | -39.6        |
| train-AverageReturn     | -61.7        |
| train-EnvExecTime       | 2.72         |
| train-MaxReturn         | -59.1        |
| train-MinReturn         | -64.1        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.8         |
| train-StdReturn         | 0.914        |
------------------------------------------

 ---------------- Iteration 149 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 149          |
| ItrTime                 | 17.1         |
| LossAfter               | -0.10247227  |
| LossBefore              | -0.004900421 |
| Time                    | 2.57e+03     |
| Time-Optimization       | 0.266        |
| Time-SampleProc         | 0.024        |
| Time-Sampling           | 16.8         |
| n_timesteps             | 1500000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.74         |
| train-MaxReturn         | -58.7        |
| train-MinReturn         | -64.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.8         |
| train-StdReturn         | 1.07         |
------------------------------------------

 ---------------- Iteration 150 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 150          |
| ItrTime                 | 17.3         |
| LossAfter               | -0.048606005 |
| LossBefore              | -0.007138312 |
| Time                    | 2.59e+03     |
| Time-Optimization       | 0.271        |
| Time-SampleProc         | 0.03         |
| Time-Sampling           | 17           |
| n_timesteps             | 1510000      |
| train-AverageDiscoun... | -39.2        |
| train-AverageReturn     | -61.3        |
| train-EnvExecTime       | 2.8          |
| train-MaxReturn         | -58          |
| train-MinReturn         | -64.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14           |
| train-StdReturn         | 1.12         |
------------------------------------------

 ---------------- Iteration 151 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 151            |
| ItrTime                 | 17.2           |
| LossAfter               | -0.023332816   |
| LossBefore              | -0.00037394103 |
| Time                    | 2.61e+03       |
| Time-Optimization       | 0.259          |
| Time-SampleProc         | 0.023          |
| Time-Sampling           | 16.9           |
| n_timesteps             | 1520000        |
| train-AverageDiscoun... | -39.4          |
| train-AverageReturn     | -61.5          |
| train-EnvExecTime       | 2.73           |
| train-MaxReturn         | -59            |
| train-MinReturn         | -64.4          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 13.9           |
| train-StdReturn         | 1.11           |
--------------------------------------------

 ---------------- Iteration 152 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 152         |
| ItrTime                 | 17.5        |
| LossAfter               | 0.007360541 |
| LossBefore              | 0.007919098 |
| Time                    | 2.62e+03    |
| Time-Optimization       | 0.3         |
| Time-SampleProc         | 0.066       |
| Time-Sampling           | 17.2        |
| n_timesteps             | 1530000     |
| train-AverageDiscoun... | -39.6       |
| train-AverageReturn     | -61.6       |
| train-EnvExecTime       | 2.7         |
| train-MaxReturn         | -58.7       |
| train-MinReturn         | -63.9       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.2        |
| train-StdReturn         | 0.909       |
-----------------------------------------

 ---------------- Iteration 153 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 153          |
| ItrTime                 | 17.1         |
| LossAfter               | -0.003265924 |
| LossBefore              | 0.0068022707 |
| Time                    | 2.64e+03     |
| Time-Optimization       | 0.268        |
| Time-SampleProc         | 0.024        |
| Time-Sampling           | 16.8         |
| n_timesteps             | 1540000      |
| train-AverageDiscoun... | -39.6        |
| train-AverageReturn     | -61.6        |
| train-EnvExecTime       | 2.68         |
| train-MaxReturn         | -59.1        |
| train-MinReturn         | -64.7        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.8         |
| train-StdReturn         | 1.22         |
------------------------------------------

 ---------------- Iteration 154 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 154          |
| ItrTime                 | 17.5         |
| LossAfter               | -0.013208366 |
| LossBefore              | 0.004949167  |
| Time                    | 2.66e+03     |
| Time-Optimization       | 0.268        |
| Time-SampleProc         | 0.021        |
| Time-Sampling           | 17.2         |
| n_timesteps             | 1550000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.4        |
| train-EnvExecTime       | 2.72         |
| train-MaxReturn         | -58.8        |
| train-MinReturn         | -65.4        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 1.31         |
------------------------------------------

 ---------------- Iteration 155 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 155          |
| ItrTime                 | 17.3         |
| LossAfter               | -0.049506932 |
| LossBefore              | -0.01860827  |
| Time                    | 2.68e+03     |
| Time-Optimization       | 0.254        |
| Time-SampleProc         | 0.023        |
| Time-Sampling           | 17           |
| n_timesteps             | 1560000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.65         |
| train-MaxReturn         | -58.1        |
| train-MinReturn         | -65.7        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 1.26         |
------------------------------------------

 ---------------- Iteration 156 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 156          |
| ItrTime                 | 16.9         |
| LossAfter               | -0.028809216 |
| LossBefore              | 0.011505619  |
| Time                    | 2.69e+03     |
| Time-Optimization       | 0.257        |
| Time-SampleProc         | 0.025        |
| Time-Sampling           | 16.6         |
| n_timesteps             | 1570000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.4        |
| train-EnvExecTime       | 2.68         |
| train-MaxReturn         | -58.4        |
| train-MinReturn         | -64.7        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.6         |
| train-StdReturn         | 1.17         |
------------------------------------------

 ---------------- Iteration 157 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 157          |
| ItrTime                 | 17.6         |
| LossAfter               | -0.027958782 |
| LossBefore              | -0.009269165 |
| Time                    | 2.71e+03     |
| Time-Optimization       | 0.262        |
| Time-SampleProc         | 0.025        |
| Time-Sampling           | 17.3         |
| n_timesteps             | 1580000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.4        |
| train-EnvExecTime       | 2.82         |
| train-MaxReturn         | -58.4        |
| train-MinReturn         | -65.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 1.26         |
------------------------------------------

 ---------------- Iteration 158 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 158          |
| ItrTime                 | 17.7         |
| LossAfter               | -0.06544659  |
| LossBefore              | -0.018835882 |
| Time                    | 2.73e+03     |
| Time-Optimization       | 0.269        |
| Time-SampleProc         | 0.029        |
| Time-Sampling           | 17.4         |
| n_timesteps             | 1590000      |
| train-AverageDiscoun... | -39.2        |
| train-AverageReturn     | -61.2        |
| train-EnvExecTime       | 2.79         |
| train-MaxReturn         | -58          |
| train-MinReturn         | -64.1        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.3         |
| train-StdReturn         | 1.14         |
------------------------------------------

 ---------------- Iteration 159 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 159         |
| ItrTime                 | 17          |
| LossAfter               | -0.00622153 |
| LossBefore              | 0.017222479 |
| Time                    | 2.75e+03    |
| Time-Optimization       | 0.263       |
| Time-SampleProc         | 0.03        |
| Time-Sampling           | 16.7        |
| n_timesteps             | 1600000     |
| train-AverageDiscoun... | -39.5       |
| train-AverageReturn     | -61.5       |
| train-EnvExecTime       | 2.78        |
| train-MaxReturn         | -58.9       |
| train-MinReturn         | -63.8       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 13.7        |
| train-StdReturn         | 0.941       |
-----------------------------------------

 ---------------- Iteration 160 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 160           |
| ItrTime                 | 17.1          |
| LossAfter               | -0.0077434448 |
| LossBefore              | 0.00041951294 |
| Time                    | 2.76e+03      |
| Time-Optimization       | 0.26          |
| Time-SampleProc         | 0.032         |
| Time-Sampling           | 16.8          |
| n_timesteps             | 1610000       |
| train-AverageDiscoun... | -39.5         |
| train-AverageReturn     | -61.5         |
| train-EnvExecTime       | 2.77          |
| train-MaxReturn         | -57.5         |
| train-MinReturn         | -65.3         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 13.7          |
| train-StdReturn         | 1.11          |
-------------------------------------------

 ---------------- Iteration 161 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 161          |
| ItrTime                 | 17.4         |
| LossAfter               | -0.032239698 |
| LossBefore              | -0.014723193 |
| Time                    | 2.78e+03     |
| Time-Optimization       | 0.264        |
| Time-SampleProc         | 0.029        |
| Time-Sampling           | 17.1         |
| n_timesteps             | 1620000      |
| train-AverageDiscoun... | -39.5        |
| train-AverageReturn     | -61.6        |
| train-EnvExecTime       | 2.87         |
| train-MaxReturn         | -59.2        |
| train-MinReturn         | -64.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14           |
| train-StdReturn         | 1.07         |
------------------------------------------

 ---------------- Iteration 162 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 162          |
| ItrTime                 | 17.4         |
| LossAfter               | -0.01946192  |
| LossBefore              | 0.0041825776 |
| Time                    | 2.8e+03      |
| Time-Optimization       | 0.254        |
| Time-SampleProc         | 0.03         |
| Time-Sampling           | 17.1         |
| n_timesteps             | 1630000      |
| train-AverageDiscoun... | -39.2        |
| train-AverageReturn     | -61.3        |
| train-EnvExecTime       | 2.9          |
| train-MaxReturn         | -57.8        |
| train-MinReturn         | -64          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14           |
| train-StdReturn         | 1.12         |
------------------------------------------

 ---------------- Iteration 163 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 163         |
| ItrTime                 | 17.4        |
| LossAfter               | -0.03494623 |
| LossBefore              | 0.010325287 |
| Time                    | 2.81e+03    |
| Time-Optimization       | 0.253       |
| Time-SampleProc         | 0.025       |
| Time-Sampling           | 17.1        |
| n_timesteps             | 1640000     |
| train-AverageDiscoun... | -39.5       |
| train-AverageReturn     | -61.5       |
| train-EnvExecTime       | 2.75        |
| train-MaxReturn         | -58.3       |
| train-MinReturn         | -64.9       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 1.06        |
-----------------------------------------

 ---------------- Iteration 164 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 164           |
| ItrTime                 | 17            |
| LossAfter               | -0.045493927  |
| LossBefore              | -0.0136644775 |
| Time                    | 2.83e+03      |
| Time-Optimization       | 0.256         |
| Time-SampleProc         | 0.021         |
| Time-Sampling           | 16.7          |
| n_timesteps             | 1650000       |
| train-AverageDiscoun... | -39.4         |
| train-AverageReturn     | -61.5         |
| train-EnvExecTime       | 2.7           |
| train-MaxReturn         | -58.1         |
| train-MinReturn         | -64.8         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 13.7          |
| train-StdReturn         | 1.21          |
-------------------------------------------

 ---------------- Iteration 165 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 165          |
| ItrTime                 | 17.1         |
| LossAfter               | -0.036531683 |
| LossBefore              | -0.018580634 |
| Time                    | 2.85e+03     |
| Time-Optimization       | 0.259        |
| Time-SampleProc         | 0.029        |
| Time-Sampling           | 16.9         |
| n_timesteps             | 1660000      |
| train-AverageDiscoun... | -39.5        |
| train-AverageReturn     | -61.6        |
| train-EnvExecTime       | 2.69         |
| train-MaxReturn         | -59.1        |
| train-MinReturn         | -64.3        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.9         |
| train-StdReturn         | 1.19         |
------------------------------------------

 ---------------- Iteration 166 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 166          |
| ItrTime                 | 17.4         |
| LossAfter               | -0.038823005 |
| LossBefore              | 0.0017194793 |
| Time                    | 2.87e+03     |
| Time-Optimization       | 0.254        |
| Time-SampleProc         | 0.029        |
| Time-Sampling           | 17.2         |
| n_timesteps             | 1670000      |
| train-AverageDiscoun... | -39.5        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.68         |
| train-MaxReturn         | -58.7        |
| train-MinReturn         | -65.9        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 1.21         |
------------------------------------------

 ---------------- Iteration 167 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 167         |
| ItrTime                 | 17.4        |
| LossAfter               | 0.009772248 |
| LossBefore              | 0.02056062  |
| Time                    | 2.88e+03    |
| Time-Optimization       | 0.258       |
| Time-SampleProc         | 0.028       |
| Time-Sampling           | 17.1        |
| n_timesteps             | 1680000     |
| train-AverageDiscoun... | -39.6       |
| train-AverageReturn     | -61.6       |
| train-EnvExecTime       | 2.69        |
| train-MaxReturn         | -58.7       |
| train-MinReturn         | -64         |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.2        |
| train-StdReturn         | 1.1         |
-----------------------------------------

 ---------------- Iteration 168 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 168          |
| ItrTime                 | 17.3         |
| LossAfter               | -0.006872815 |
| LossBefore              | 0.040325984  |
| Time                    | 2.9e+03      |
| Time-Optimization       | 0.251        |
| Time-SampleProc         | 0.023        |
| Time-Sampling           | 17           |
| n_timesteps             | 1690000      |
| train-AverageDiscoun... | -39.3        |
| train-AverageReturn     | -61.4        |
| train-EnvExecTime       | 2.77         |
| train-MaxReturn         | -58.8        |
| train-MinReturn         | -64          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14           |
| train-StdReturn         | 0.984        |
------------------------------------------

 ---------------- Iteration 169 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 169          |
| ItrTime                 | 17.2         |
| LossAfter               | -0.016496643 |
| LossBefore              | -0.020257238 |
| Time                    | 2.92e+03     |
| Time-Optimization       | 0.254        |
| Time-SampleProc         | 0.025        |
| Time-Sampling           | 17           |
| n_timesteps             | 1700000      |
| train-AverageDiscoun... | -39.3        |
| train-AverageReturn     | -61.3        |
| train-EnvExecTime       | 2.75         |
| train-MaxReturn         | -57.9        |
| train-MinReturn         | -64.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.9         |
| train-StdReturn         | 1.24         |
------------------------------------------

 ---------------- Iteration 170 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 170           |
| ItrTime                 | 17.2          |
| LossAfter               | -0.027496707  |
| LossBefore              | -0.0011552277 |
| Time                    | 2.94e+03      |
| Time-Optimization       | 0.255         |
| Time-SampleProc         | 0.026         |
| Time-Sampling           | 17            |
| n_timesteps             | 1710000       |
| train-AverageDiscoun... | -39.4         |
| train-AverageReturn     | -61.4         |
| train-EnvExecTime       | 2.75          |
| train-MaxReturn         | -57.8         |
| train-MinReturn         | -65.1         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 13.9          |
| train-StdReturn         | 1.21          |
-------------------------------------------

 ---------------- Iteration 171 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 171          |
| ItrTime                 | 17.1         |
| LossAfter               | -0.038780786 |
| LossBefore              | 0.0045207674 |
| Time                    | 2.95e+03     |
| Time-Optimization       | 0.255        |
| Time-SampleProc         | 0.029        |
| Time-Sampling           | 16.8         |
| n_timesteps             | 1720000      |
| train-AverageDiscoun... | -39.5        |
| train-AverageReturn     | -61.6        |
| train-EnvExecTime       | 2.72         |
| train-MaxReturn         | -59          |
| train-MinReturn         | -64.9        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.9         |
| train-StdReturn         | 1.08         |
------------------------------------------

 ---------------- Iteration 172 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 172           |
| ItrTime                 | 17.6          |
| LossAfter               | -0.040052716  |
| LossBefore              | -0.0021086303 |
| Time                    | 2.97e+03      |
| Time-Optimization       | 0.262         |
| Time-SampleProc         | 0.025         |
| Time-Sampling           | 17.3          |
| n_timesteps             | 1730000       |
| train-AverageDiscoun... | -39.4         |
| train-AverageReturn     | -61.4         |
| train-EnvExecTime       | 2.76          |
| train-MaxReturn         | -58.5         |
| train-MinReturn         | -64.8         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.3          |
| train-StdReturn         | 1.24          |
-------------------------------------------

 ---------------- Iteration 173 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 173          |
| ItrTime                 | 17.5         |
| LossAfter               | -0.017006325 |
| LossBefore              | -0.005581015 |
| Time                    | 2.99e+03     |
| Time-Optimization       | 0.261        |
| Time-SampleProc         | 0.026        |
| Time-Sampling           | 17.2         |
| n_timesteps             | 1740000      |
| train-AverageDiscoun... | -39.3        |
| train-AverageReturn     | -61.4        |
| train-EnvExecTime       | 2.71         |
| train-MaxReturn         | -58.9        |
| train-MinReturn         | -63.9        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 1.15         |
------------------------------------------

 ---------------- Iteration 174 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 174           |
| ItrTime                 | 17.2          |
| LossAfter               | -0.0409623    |
| LossBefore              | -0.0104853455 |
| Time                    | 3.01e+03      |
| Time-Optimization       | 0.257         |
| Time-SampleProc         | 0.029         |
| Time-Sampling           | 16.9          |
| n_timesteps             | 1750000       |
| train-AverageDiscoun... | -39.6         |
| train-AverageReturn     | -61.6         |
| train-EnvExecTime       | 2.76          |
| train-MaxReturn         | -58.8         |
| train-MinReturn         | -64.2         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 13.9          |
| train-StdReturn         | 1.12          |
-------------------------------------------

 ---------------- Iteration 175 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 175          |
| ItrTime                 | 17.1         |
| LossAfter               | 0.0040100706 |
| LossBefore              | 0.012884869  |
| Time                    | 3.02e+03     |
| Time-Optimization       | 0.26         |
| Time-SampleProc         | 0.022        |
| Time-Sampling           | 16.8         |
| n_timesteps             | 1760000      |
| train-AverageDiscoun... | -39.5        |
| train-AverageReturn     | -61.6        |
| train-EnvExecTime       | 2.76         |
| train-MaxReturn         | -59.3        |
| train-MinReturn         | -65          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.8         |
| train-StdReturn         | 1.02         |
------------------------------------------

 ---------------- Iteration 176 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 176           |
| ItrTime                 | 17.2          |
| LossAfter               | -0.03319841   |
| LossBefore              | -0.0105689205 |
| Time                    | 3.04e+03      |
| Time-Optimization       | 0.261         |
| Time-SampleProc         | 0.021         |
| Time-Sampling           | 16.9          |
| n_timesteps             | 1770000       |
| train-AverageDiscoun... | -39.3         |
| train-AverageReturn     | -61.3         |
| train-EnvExecTime       | 2.73          |
| train-MaxReturn         | -58.1         |
| train-MinReturn         | -64.4         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 13.9          |
| train-StdReturn         | 1.2           |
-------------------------------------------

 ---------------- Iteration 177 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 177           |
| ItrTime                 | 17.5          |
| LossAfter               | -0.012209113  |
| LossBefore              | -0.0030439498 |
| Time                    | 3.06e+03      |
| Time-Optimization       | 0.254         |
| Time-SampleProc         | 0.03          |
| Time-Sampling           | 17.3          |
| n_timesteps             | 1780000       |
| train-AverageDiscoun... | -39.5         |
| train-AverageReturn     | -61.6         |
| train-EnvExecTime       | 2.69          |
| train-MaxReturn         | -59.2         |
| train-MinReturn         | -65.7         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.3          |
| train-StdReturn         | 1.14          |
-------------------------------------------

 ---------------- Iteration 178 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 178         |
| ItrTime                 | 17.5        |
| LossAfter               | -0.03952186 |
| LossBefore              | -0.01118801 |
| Time                    | 3.07e+03    |
| Time-Optimization       | 0.264       |
| Time-SampleProc         | 0.027       |
| Time-Sampling           | 17.2        |
| n_timesteps             | 1790000     |
| train-AverageDiscoun... | -39.4       |
| train-AverageReturn     | -61.5       |
| train-EnvExecTime       | 2.76        |
| train-MaxReturn         | -58.4       |
| train-MinReturn         | -65.3       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.2        |
| train-StdReturn         | 1.17        |
-----------------------------------------

 ---------------- Iteration 179 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 179         |
| ItrTime                 | 17.1        |
| LossAfter               | 0.009472303 |
| LossBefore              | 0.0272057   |
| Time                    | 3.09e+03    |
| Time-Optimization       | 0.259       |
| Time-SampleProc         | 0.029       |
| Time-Sampling           | 16.8        |
| n_timesteps             | 1800000     |
| train-AverageDiscoun... | -39.5       |
| train-AverageReturn     | -61.6       |
| train-EnvExecTime       | 2.74        |
| train-MaxReturn         | -58.1       |
| train-MinReturn         | -66.1       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 13.9        |
| train-StdReturn         | 1.21        |
-----------------------------------------

 ---------------- Iteration 180 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 180          |
| ItrTime                 | 17.4         |
| LossAfter               | -0.02032358  |
| LossBefore              | -0.017213339 |
| Time                    | 3.11e+03     |
| Time-Optimization       | 0.253        |
| Time-SampleProc         | 0.026        |
| Time-Sampling           | 17.1         |
| n_timesteps             | 1810000      |
| train-AverageDiscoun... | -39.6        |
| train-AverageReturn     | -61.7        |
| train-EnvExecTime       | 2.73         |
| train-MaxReturn         | -58.1        |
| train-MinReturn         | -64.4        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 1.08         |
------------------------------------------

 ---------------- Iteration 181 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 181          |
| ItrTime                 | 17.1         |
| LossAfter               | -0.020957869 |
| LossBefore              | 0.007124309  |
| Time                    | 3.13e+03     |
| Time-Optimization       | 0.271        |
| Time-SampleProc         | 0.028        |
| Time-Sampling           | 16.8         |
| n_timesteps             | 1820000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.4        |
| train-EnvExecTime       | 2.75         |
| train-MaxReturn         | -57.6        |
| train-MinReturn         | -64.1        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.8         |
| train-StdReturn         | 1.17         |
------------------------------------------

 ---------------- Iteration 182 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 182         |
| ItrTime                 | 17.1        |
| LossAfter               | 0.018944543 |
| LossBefore              | 0.028706724 |
| Time                    | 3.14e+03    |
| Time-Optimization       | 0.261       |
| Time-SampleProc         | 0.025       |
| Time-Sampling           | 16.8        |
| n_timesteps             | 1830000     |
| train-AverageDiscoun... | -39.4       |
| train-AverageReturn     | -61.4       |
| train-EnvExecTime       | 2.7         |
| train-MaxReturn         | -58.3       |
| train-MinReturn         | -63.7       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 13.8        |
| train-StdReturn         | 1.02        |
-----------------------------------------

 ---------------- Iteration 183 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 183          |
| ItrTime                 | 17.2         |
| LossAfter               | -0.03653645  |
| LossBefore              | -0.000877124 |
| Time                    | 3.16e+03     |
| Time-Optimization       | 0.257        |
| Time-SampleProc         | 0.03         |
| Time-Sampling           | 16.9         |
| n_timesteps             | 1840000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.4        |
| train-EnvExecTime       | 2.71         |
| train-MaxReturn         | -57.4        |
| train-MinReturn         | -65.1        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.9         |
| train-StdReturn         | 1.23         |
------------------------------------------

 ---------------- Iteration 184 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 184          |
| ItrTime                 | 17.4         |
| LossAfter               | -0.035878673 |
| LossBefore              | 0.0013311035 |
| Time                    | 3.18e+03     |
| Time-Optimization       | 0.261        |
| Time-SampleProc         | 0.022        |
| Time-Sampling           | 17.1         |
| n_timesteps             | 1850000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.4        |
| train-EnvExecTime       | 2.73         |
| train-MaxReturn         | -59.1        |
| train-MinReturn         | -64.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 0.986        |
------------------------------------------

 ---------------- Iteration 185 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 185          |
| ItrTime                 | 17.6         |
| LossAfter               | -0.016434968 |
| LossBefore              | 0.0068054902 |
| Time                    | 3.2e+03      |
| Time-Optimization       | 0.259        |
| Time-SampleProc         | 0.026        |
| Time-Sampling           | 17.3         |
| n_timesteps             | 1860000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.7          |
| train-MaxReturn         | -58.6        |
| train-MinReturn         | -65.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.3         |
| train-StdReturn         | 1.19         |
------------------------------------------

 ---------------- Iteration 186 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 186          |
| ItrTime                 | 17.1         |
| LossAfter               | -0.03890232  |
| LossBefore              | -0.015558995 |
| Time                    | 3.21e+03     |
| Time-Optimization       | 0.285        |
| Time-SampleProc         | 0.028        |
| Time-Sampling           | 16.8         |
| n_timesteps             | 1870000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.66         |
| train-MaxReturn         | -58.5        |
| train-MinReturn         | -64.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.8         |
| train-StdReturn         | 1.28         |
------------------------------------------

 ---------------- Iteration 187 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 187          |
| ItrTime                 | 17.5         |
| LossAfter               | -0.016795374 |
| LossBefore              | 0.008328961  |
| Time                    | 3.23e+03     |
| Time-Optimization       | 0.259        |
| Time-SampleProc         | 0.029        |
| Time-Sampling           | 17.2         |
| n_timesteps             | 1880000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.4        |
| train-EnvExecTime       | 2.74         |
| train-MaxReturn         | -58.8        |
| train-MinReturn         | -64.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 1.12         |
------------------------------------------

 ---------------- Iteration 188 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 188           |
| ItrTime                 | 17.2          |
| LossAfter               | -0.06762614   |
| LossBefore              | -0.0022378785 |
| Time                    | 3.25e+03      |
| Time-Optimization       | 0.256         |
| Time-SampleProc         | 0.028         |
| Time-Sampling           | 17            |
| n_timesteps             | 1890000       |
| train-AverageDiscoun... | -39.4         |
| train-AverageReturn     | -61.4         |
| train-EnvExecTime       | 2.67          |
| train-MaxReturn         | -57.9         |
| train-MinReturn         | -64.7         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14            |
| train-StdReturn         | 1.23          |
-------------------------------------------

 ---------------- Iteration 189 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 189          |
| ItrTime                 | 17.1         |
| LossAfter               | -0.05123557  |
| LossBefore              | -0.009268808 |
| Time                    | 3.26e+03     |
| Time-Optimization       | 0.259        |
| Time-SampleProc         | 0.02         |
| Time-Sampling           | 16.9         |
| n_timesteps             | 1900000      |
| train-AverageDiscoun... | -39.5        |
| train-AverageReturn     | -61.6        |
| train-EnvExecTime       | 2.72         |
| train-MaxReturn         | -57.9        |
| train-MinReturn         | -64.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.9         |
| train-StdReturn         | 1.16         |
------------------------------------------

 ---------------- Iteration 190 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 190          |
| ItrTime                 | 17.4         |
| LossAfter               | -0.024348853 |
| LossBefore              | -0.012268592 |
| Time                    | 3.28e+03     |
| Time-Optimization       | 0.258        |
| Time-SampleProc         | 0.023        |
| Time-Sampling           | 17.1         |
| n_timesteps             | 1910000      |
| train-AverageDiscoun... | -39.3        |
| train-AverageReturn     | -61.3        |
| train-EnvExecTime       | 2.72         |
| train-MaxReturn         | -58.9        |
| train-MinReturn         | -65.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 1.18         |
------------------------------------------

 ---------------- Iteration 191 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 191           |
| ItrTime                 | 17.4          |
| LossAfter               | -0.043869384  |
| LossBefore              | -0.0053234133 |
| Time                    | 3.3e+03       |
| Time-Optimization       | 0.255         |
| Time-SampleProc         | 0.021         |
| Time-Sampling           | 17.1          |
| n_timesteps             | 1920000       |
| train-AverageDiscoun... | -39.3         |
| train-AverageReturn     | -61.4         |
| train-EnvExecTime       | 2.77          |
| train-MaxReturn         | -57.7         |
| train-MinReturn         | -65.1         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14            |
| train-StdReturn         | 1.22          |
-------------------------------------------

 ---------------- Iteration 192 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 192          |
| ItrTime                 | 17           |
| LossAfter               | -0.026177384 |
| LossBefore              | -0.005948099 |
| Time                    | 3.32e+03     |
| Time-Optimization       | 0.252        |
| Time-SampleProc         | 0.023        |
| Time-Sampling           | 16.8         |
| n_timesteps             | 1930000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.71         |
| train-MaxReturn         | -58.6        |
| train-MinReturn         | -64.9        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.8         |
| train-StdReturn         | 1.27         |
------------------------------------------

 ---------------- Iteration 193 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 193          |
| ItrTime                 | 17.2         |
| LossAfter               | -0.041284967 |
| LossBefore              | 0.012937262  |
| Time                    | 3.33e+03     |
| Time-Optimization       | 0.261        |
| Time-SampleProc         | 0.02         |
| Time-Sampling           | 16.9         |
| n_timesteps             | 1940000      |
| train-AverageDiscoun... | -39.3        |
| train-AverageReturn     | -61.4        |
| train-EnvExecTime       | 2.72         |
| train-MaxReturn         | -58.8        |
| train-MinReturn         | -64.7        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.9         |
| train-StdReturn         | 1.16         |
------------------------------------------

 ---------------- Iteration 194 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 194         |
| ItrTime                 | 17.4        |
| LossAfter               | -0.04035204 |
| LossBefore              | 0.010881961 |
| Time                    | 3.35e+03    |
| Time-Optimization       | 0.25        |
| Time-SampleProc         | 0.031       |
| Time-Sampling           | 17.2        |
| n_timesteps             | 1950000     |
| train-AverageDiscoun... | -39.4       |
| train-AverageReturn     | -61.5       |
| train-EnvExecTime       | 2.75        |
| train-MaxReturn         | -58.9       |
| train-MinReturn         | -64.4       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 1.03        |
-----------------------------------------

 ---------------- Iteration 195 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 195           |
| ItrTime                 | 17.5          |
| LossAfter               | -0.029020099  |
| LossBefore              | -0.0044050002 |
| Time                    | 3.37e+03      |
| Time-Optimization       | 0.256         |
| Time-SampleProc         | 0.03          |
| Time-Sampling           | 17.2          |
| n_timesteps             | 1960000       |
| train-AverageDiscoun... | -39.4         |
| train-AverageReturn     | -61.5         |
| train-EnvExecTime       | 2.74          |
| train-MaxReturn         | -59.4         |
| train-MinReturn         | -63.5         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.2          |
| train-StdReturn         | 0.978         |
-------------------------------------------

 ---------------- Iteration 196 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 196          |
| ItrTime                 | 17.1         |
| LossAfter               | -0.027248492 |
| LossBefore              | 0.0134225115 |
| Time                    | 3.39e+03     |
| Time-Optimization       | 0.261        |
| Time-SampleProc         | 0.021        |
| Time-Sampling           | 16.8         |
| n_timesteps             | 1970000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.7          |
| train-MaxReturn         | -59.3        |
| train-MinReturn         | -64.7        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.9         |
| train-StdReturn         | 0.996        |
------------------------------------------

 ---------------- Iteration 197 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 197          |
| ItrTime                 | 17.2         |
| LossAfter               | -0.024342267 |
| LossBefore              | 0.0027659547 |
| Time                    | 3.4e+03      |
| Time-Optimization       | 0.336        |
| Time-SampleProc         | 0.028        |
| Time-Sampling           | 16.9         |
| n_timesteps             | 1980000      |
| train-AverageDiscoun... | -39.3        |
| train-AverageReturn     | -61.4        |
| train-EnvExecTime       | 2.73         |
| train-MaxReturn         | -58.5        |
| train-MinReturn         | -65          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.9         |
| train-StdReturn         | 1.15         |
------------------------------------------

 ---------------- Iteration 198 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 198           |
| ItrTime                 | 17.9          |
| LossAfter               | 0.00094135135 |
| LossBefore              | 0.010770636   |
| Time                    | 3.42e+03      |
| Time-Optimization       | 0.258         |
| Time-SampleProc         | 0.03          |
| Time-Sampling           | 17.6          |
| n_timesteps             | 1990000       |
| train-AverageDiscoun... | -39.3         |
| train-AverageReturn     | -61.3         |
| train-EnvExecTime       | 2.87          |
| train-MaxReturn         | -57.2         |
| train-MinReturn         | -65           |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.4          |
| train-StdReturn         | 1.19          |
-------------------------------------------

 ---------------- Iteration 199 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 199          |
| ItrTime                 | 18.1         |
| LossAfter               | -0.024094163 |
| LossBefore              | -0.00883699  |
| Time                    | 3.44e+03     |
| Time-Optimization       | 0.257        |
| Time-SampleProc         | 0.085        |
| Time-Sampling           | 17.8         |
| n_timesteps             | 2000000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.73         |
| train-MaxReturn         | -58.9        |
| train-MinReturn         | -64.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.8         |
| train-StdReturn         | 1.11         |
------------------------------------------

 ---------------- Iteration 200 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 200           |
| ItrTime                 | 17.1          |
| LossAfter               | 0.00095987855 |
| LossBefore              | 0.01897811    |
| Time                    | 3.46e+03      |
| Time-Optimization       | 0.254         |
| Time-SampleProc         | 0.027         |
| Time-Sampling           | 16.8          |
| n_timesteps             | 2010000       |
| train-AverageDiscoun... | -39.4         |
| train-AverageReturn     | -61.4         |
| train-EnvExecTime       | 2.69          |
| train-MaxReturn         | -58.6         |
| train-MinReturn         | -65.7         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 13.9          |
| train-StdReturn         | 1.1           |
-------------------------------------------

 ---------------- Iteration 201 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 201           |
| ItrTime                 | 17.5          |
| LossAfter               | -0.022528796  |
| LossBefore              | -0.0069904784 |
| Time                    | 3.47e+03      |
| Time-Optimization       | 0.472         |
| Time-SampleProc         | 0.023         |
| Time-Sampling           | 17            |
| n_timesteps             | 2020000       |
| train-AverageDiscoun... | -39.6         |
| train-AverageReturn     | -61.6         |
| train-EnvExecTime       | 2.71          |
| train-MaxReturn         | -58.7         |
| train-MinReturn         | -65           |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14            |
| train-StdReturn         | 1.07          |
-------------------------------------------

 ---------------- Iteration 202 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 202         |
| ItrTime                 | 17.3        |
| LossAfter               | -0.02631501 |
| LossBefore              | 0.018045556 |
| Time                    | 3.49e+03    |
| Time-Optimization       | 0.259       |
| Time-SampleProc         | 0.024       |
| Time-Sampling           | 17.1        |
| n_timesteps             | 2030000     |
| train-AverageDiscoun... | -39.6       |
| train-AverageReturn     | -61.6       |
| train-EnvExecTime       | 2.75        |
| train-MaxReturn         | -57.8       |
| train-MinReturn         | -63.7       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14          |
| train-StdReturn         | 1.21        |
-----------------------------------------

 ---------------- Iteration 203 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 203          |
| ItrTime                 | 17.5         |
| LossAfter               | 0.0107286405 |
| LossBefore              | 0.033661548  |
| Time                    | 3.51e+03     |
| Time-Optimization       | 0.256        |
| Time-SampleProc         | 0.03         |
| Time-Sampling           | 17.2         |
| n_timesteps             | 2040000      |
| train-AverageDiscoun... | -39.5        |
| train-AverageReturn     | -61.6        |
| train-EnvExecTime       | 2.74         |
| train-MaxReturn         | -58.2        |
| train-MinReturn         | -64.5        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 1.19         |
------------------------------------------

 ---------------- Iteration 204 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 204          |
| ItrTime                 | 17.1         |
| LossAfter               | 0.0025558656 |
| LossBefore              | 0.018127527  |
| Time                    | 3.53e+03     |
| Time-Optimization       | 0.258        |
| Time-SampleProc         | 0.027        |
| Time-Sampling           | 16.8         |
| n_timesteps             | 2050000      |
| train-AverageDiscoun... | -39.3        |
| train-AverageReturn     | -61.3        |
| train-EnvExecTime       | 2.7          |
| train-MaxReturn         | -58.9        |
| train-MinReturn         | -63.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.8         |
| train-StdReturn         | 0.979        |
------------------------------------------

 ---------------- Iteration 205 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 205          |
| ItrTime                 | 17.4         |
| LossAfter               | -0.028755834 |
| LossBefore              | -0.010203406 |
| Time                    | 3.54e+03     |
| Time-Optimization       | 0.256        |
| Time-SampleProc         | 0.022        |
| Time-Sampling           | 17.1         |
| n_timesteps             | 2060000      |
| train-AverageDiscoun... | -39.5        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.69         |
| train-MaxReturn         | -58.4        |
| train-MinReturn         | -64.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 0.975        |
------------------------------------------

 ---------------- Iteration 206 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 206          |
| ItrTime                 | 17.3         |
| LossAfter               | -0.05264741  |
| LossBefore              | -0.034130823 |
| Time                    | 3.56e+03     |
| Time-Optimization       | 0.254        |
| Time-SampleProc         | 0.027        |
| Time-Sampling           | 17           |
| n_timesteps             | 2070000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.75         |
| train-MaxReturn         | -57.8        |
| train-MinReturn         | -64.7        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14           |
| train-StdReturn         | 1.11         |
------------------------------------------

 ---------------- Iteration 207 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 207           |
| ItrTime                 | 17.5          |
| LossAfter               | -0.063830845  |
| LossBefore              | -0.0065628053 |
| Time                    | 3.58e+03      |
| Time-Optimization       | 0.256         |
| Time-SampleProc         | 0.022         |
| Time-Sampling           | 17.2          |
| n_timesteps             | 2080000       |
| train-AverageDiscoun... | -39.3         |
| train-AverageReturn     | -61.3         |
| train-EnvExecTime       | 2.76          |
| train-MaxReturn         | -58.8         |
| train-MinReturn         | -65.1         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.2          |
| train-StdReturn         | 1.14          |
-------------------------------------------

 ---------------- Iteration 208 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 208          |
| ItrTime                 | 17.4         |
| LossAfter               | -0.042670775 |
| LossBefore              | -0.016336547 |
| Time                    | 3.6e+03      |
| Time-Optimization       | 0.253        |
| Time-SampleProc         | 0.021        |
| Time-Sampling           | 17.2         |
| n_timesteps             | 2090000      |
| train-AverageDiscoun... | -39.3        |
| train-AverageReturn     | -61.4        |
| train-EnvExecTime       | 2.7          |
| train-MaxReturn         | -59.2        |
| train-MinReturn         | -65          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 1.17         |
------------------------------------------

 ---------------- Iteration 209 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 209          |
| ItrTime                 | 17.5         |
| LossAfter               | -0.04114601  |
| LossBefore              | 0.0002445587 |
| Time                    | 3.61e+03     |
| Time-Optimization       | 0.259        |
| Time-SampleProc         | 0.033        |
| Time-Sampling           | 17.2         |
| n_timesteps             | 2100000      |
| train-AverageDiscoun... | -39.5        |
| train-AverageReturn     | -61.6        |
| train-EnvExecTime       | 2.68         |
| train-MaxReturn         | -59.2        |
| train-MinReturn         | -64.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 0.99         |
------------------------------------------

 ---------------- Iteration 210 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 210         |
| ItrTime                 | 17.1        |
| LossAfter               | -0.07419012 |
| LossBefore              | -0.02095824 |
| Time                    | 3.63e+03    |
| Time-Optimization       | 0.259       |
| Time-SampleProc         | 0.029       |
| Time-Sampling           | 16.8        |
| n_timesteps             | 2110000     |
| train-AverageDiscoun... | -39.5       |
| train-AverageReturn     | -61.5       |
| train-EnvExecTime       | 2.67        |
| train-MaxReturn         | -58.9       |
| train-MinReturn         | -63.9       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 13.9        |
| train-StdReturn         | 1.01        |
-----------------------------------------

 ---------------- Iteration 211 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 211           |
| ItrTime                 | 17.1          |
| LossAfter               | -0.07429344   |
| LossBefore              | -0.0019428345 |
| Time                    | 3.65e+03      |
| Time-Optimization       | 0.259         |
| Time-SampleProc         | 0.023         |
| Time-Sampling           | 16.8          |
| n_timesteps             | 2120000       |
| train-AverageDiscoun... | -39.2         |
| train-AverageReturn     | -61.2         |
| train-EnvExecTime       | 2.67          |
| train-MaxReturn         | -59.3         |
| train-MinReturn         | -64.4         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 13.9          |
| train-StdReturn         | 1.05          |
-------------------------------------------

 ---------------- Iteration 212 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 212           |
| ItrTime                 | 17.2          |
| LossAfter               | -0.0013050659 |
| LossBefore              | -0.0017285888 |
| Time                    | 3.66e+03      |
| Time-Optimization       | 0.265         |
| Time-SampleProc         | 0.021         |
| Time-Sampling           | 16.9          |
| n_timesteps             | 2130000       |
| train-AverageDiscoun... | -39.3         |
| train-AverageReturn     | -61.4         |
| train-EnvExecTime       | 2.69          |
| train-MaxReturn         | -59.2         |
| train-MinReturn         | -65.1         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 13.9          |
| train-StdReturn         | 1.05          |
-------------------------------------------

 ---------------- Iteration 213 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 213          |
| ItrTime                 | 17.6         |
| LossAfter               | -0.038665626 |
| LossBefore              | -0.017471123 |
| Time                    | 3.68e+03     |
| Time-Optimization       | 0.269        |
| Time-SampleProc         | 0.029        |
| Time-Sampling           | 17.3         |
| n_timesteps             | 2140000      |
| train-AverageDiscoun... | -39.3        |
| train-AverageReturn     | -61.4        |
| train-EnvExecTime       | 2.78         |
| train-MaxReturn         | -57.3        |
| train-MinReturn         | -65.5        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 1.27         |
------------------------------------------

 ---------------- Iteration 214 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 214          |
| ItrTime                 | 16.8         |
| LossAfter               | -0.019713499 |
| LossBefore              | -0.006164714 |
| Time                    | 3.7e+03      |
| Time-Optimization       | 0.255        |
| Time-SampleProc         | 0.02         |
| Time-Sampling           | 16.6         |
| n_timesteps             | 2150000      |
| train-AverageDiscoun... | -39.3        |
| train-AverageReturn     | -61.4        |
| train-EnvExecTime       | 2.47         |
| train-MaxReturn         | -57.7        |
| train-MinReturn         | -64.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.8         |
| train-StdReturn         | 1.08         |
------------------------------------------

 ---------------- Iteration 215 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 215          |
| ItrTime                 | 17.6         |
| LossAfter               | -0.04604155  |
| LossBefore              | -0.030793658 |
| Time                    | 3.72e+03     |
| Time-Optimization       | 0.254        |
| Time-SampleProc         | 0.03         |
| Time-Sampling           | 17.3         |
| n_timesteps             | 2160000      |
| train-AverageDiscoun... | -39.6        |
| train-AverageReturn     | -61.7        |
| train-EnvExecTime       | 2.78         |
| train-MaxReturn         | -58.1        |
| train-MinReturn         | -63.7        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.3         |
| train-StdReturn         | 1.03         |
------------------------------------------

 ---------------- Iteration 216 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 216          |
| ItrTime                 | 17           |
| LossAfter               | -0.010373796 |
| LossBefore              | 0.009179072  |
| Time                    | 3.73e+03     |
| Time-Optimization       | 0.255        |
| Time-SampleProc         | 0.021        |
| Time-Sampling           | 16.7         |
| n_timesteps             | 2170000      |
| train-AverageDiscoun... | -39.5        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.64         |
| train-MaxReturn         | -59.1        |
| train-MinReturn         | -64.5        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.8         |
| train-StdReturn         | 1.08         |
------------------------------------------

 ---------------- Iteration 217 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 217          |
| ItrTime                 | 17.6         |
| LossAfter               | -0.060360357 |
| LossBefore              | 0.021931905  |
| Time                    | 3.75e+03     |
| Time-Optimization       | 0.258        |
| Time-SampleProc         | 0.033        |
| Time-Sampling           | 17.3         |
| n_timesteps             | 2180000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.4        |
| train-EnvExecTime       | 2.76         |
| train-MaxReturn         | -58          |
| train-MinReturn         | -63.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 1.04         |
------------------------------------------

 ---------------- Iteration 218 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 218         |
| ItrTime                 | 17.6        |
| LossAfter               | -0.06327085 |
| LossBefore              | 0.009174237 |
| Time                    | 3.77e+03    |
| Time-Optimization       | 0.253       |
| Time-SampleProc         | 0.02        |
| Time-Sampling           | 17.4        |
| n_timesteps             | 2190000     |
| train-AverageDiscoun... | -39.4       |
| train-AverageReturn     | -61.5       |
| train-EnvExecTime       | 2.71        |
| train-MaxReturn         | -58.9       |
| train-MinReturn         | -65.3       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.4        |
| train-StdReturn         | 1.09        |
-----------------------------------------

 ---------------- Iteration 219 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 219          |
| ItrTime                 | 17.2         |
| LossAfter               | -0.029963514 |
| LossBefore              | -0.011842654 |
| Time                    | 3.79e+03     |
| Time-Optimization       | 0.255        |
| Time-SampleProc         | 0.023        |
| Time-Sampling           | 17           |
| n_timesteps             | 2200000      |
| train-AverageDiscoun... | -39.3        |
| train-AverageReturn     | -61.3        |
| train-EnvExecTime       | 2.69         |
| train-MaxReturn         | -58.7        |
| train-MinReturn         | -63.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14           |
| train-StdReturn         | 1.11         |
------------------------------------------

 ---------------- Iteration 220 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 220          |
| ItrTime                 | 17.1         |
| LossAfter               | -0.020886764 |
| LossBefore              | 0.022491695  |
| Time                    | 3.8e+03      |
| Time-Optimization       | 0.252        |
| Time-SampleProc         | 0.026        |
| Time-Sampling           | 16.8         |
| n_timesteps             | 2210000      |
| train-AverageDiscoun... | -39.5        |
| train-AverageReturn     | -61.6        |
| train-EnvExecTime       | 2.63         |
| train-MaxReturn         | -58.2        |
| train-MinReturn         | -64.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.9         |
| train-StdReturn         | 1.26         |
------------------------------------------

 ---------------- Iteration 221 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 221           |
| ItrTime                 | 17.2          |
| LossAfter               | -0.023445264  |
| LossBefore              | -0.0023403352 |
| Time                    | 3.82e+03      |
| Time-Optimization       | 0.265         |
| Time-SampleProc         | 0.025         |
| Time-Sampling           | 16.9          |
| n_timesteps             | 2220000       |
| train-AverageDiscoun... | -39.5         |
| train-AverageReturn     | -61.6         |
| train-EnvExecTime       | 2.63          |
| train-MaxReturn         | -58.7         |
| train-MinReturn         | -64.9         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14            |
| train-StdReturn         | 1.1           |
-------------------------------------------

 ---------------- Iteration 222 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 222         |
| ItrTime                 | 17.1        |
| LossAfter               | -0.07045631 |
| LossBefore              | 0.009608371 |
| Time                    | 3.84e+03    |
| Time-Optimization       | 0.256       |
| Time-SampleProc         | 0.024       |
| Time-Sampling           | 16.8        |
| n_timesteps             | 2230000     |
| train-AverageDiscoun... | -39.3       |
| train-AverageReturn     | -61.3       |
| train-EnvExecTime       | 2.65        |
| train-MaxReturn         | -58.2       |
| train-MinReturn         | -63.5       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 13.9        |
| train-StdReturn         | 0.985       |
-----------------------------------------

 ---------------- Iteration 223 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 223          |
| ItrTime                 | 17.5         |
| LossAfter               | -0.07335313  |
| LossBefore              | -0.009964795 |
| Time                    | 3.85e+03     |
| Time-Optimization       | 0.268        |
| Time-SampleProc         | 0.021        |
| Time-Sampling           | 17.3         |
| n_timesteps             | 2240000      |
| train-AverageDiscoun... | -39.5        |
| train-AverageReturn     | -61.6        |
| train-EnvExecTime       | 2.75         |
| train-MaxReturn         | -58.9        |
| train-MinReturn         | -65.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 1.1          |
------------------------------------------

 ---------------- Iteration 224 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 224           |
| ItrTime                 | 17.4          |
| LossAfter               | -0.033106975  |
| LossBefore              | -0.0016813598 |
| Time                    | 3.87e+03      |
| Time-Optimization       | 0.255         |
| Time-SampleProc         | 0.025         |
| Time-Sampling           | 17.1          |
| n_timesteps             | 2250000       |
| train-AverageDiscoun... | -39.4         |
| train-AverageReturn     | -61.5         |
| train-EnvExecTime       | 2.75          |
| train-MaxReturn         | -58.8         |
| train-MinReturn         | -66.3         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 1.15          |
-------------------------------------------

 ---------------- Iteration 225 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 225         |
| ItrTime                 | 17.3        |
| LossAfter               | 0.01807301  |
| LossBefore              | 0.019107254 |
| Time                    | 3.89e+03    |
| Time-Optimization       | 0.251       |
| Time-SampleProc         | 0.031       |
| Time-Sampling           | 17.1        |
| n_timesteps             | 2260000     |
| train-AverageDiscoun... | -39.4       |
| train-AverageReturn     | -61.4       |
| train-EnvExecTime       | 2.64        |
| train-MaxReturn         | -58.3       |
| train-MinReturn         | -64.6       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.1        |
| train-StdReturn         | 1.14        |
-----------------------------------------

 ---------------- Iteration 226 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 226            |
| ItrTime                 | 17.5           |
| LossAfter               | -0.013013226   |
| LossBefore              | -0.00076699216 |
| Time                    | 3.91e+03       |
| Time-Optimization       | 0.258          |
| Time-SampleProc         | 0.021          |
| Time-Sampling           | 17.2           |
| n_timesteps             | 2270000        |
| train-AverageDiscoun... | -39.5          |
| train-AverageReturn     | -61.5          |
| train-EnvExecTime       | 2.74           |
| train-MaxReturn         | -57.4          |
| train-MinReturn         | -64.3          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 14.2           |
| train-StdReturn         | 1.22           |
--------------------------------------------

 ---------------- Iteration 227 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 227          |
| ItrTime                 | 17.6         |
| LossAfter               | -0.061144922 |
| LossBefore              | -0.021843342 |
| Time                    | 3.92e+03     |
| Time-Optimization       | 0.255        |
| Time-SampleProc         | 0.025        |
| Time-Sampling           | 17.3         |
| n_timesteps             | 2280000      |
| train-AverageDiscoun... | -39.2        |
| train-AverageReturn     | -61.3        |
| train-EnvExecTime       | 2.77         |
| train-MaxReturn         | -58.6        |
| train-MinReturn         | -64.4        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 1.1          |
------------------------------------------

 ---------------- Iteration 228 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 228          |
| ItrTime                 | 17.3         |
| LossAfter               | -0.016241932 |
| LossBefore              | 0.0069813323 |
| Time                    | 3.94e+03     |
| Time-Optimization       | 0.254        |
| Time-SampleProc         | 0.031        |
| Time-Sampling           | 17           |
| n_timesteps             | 2290000      |
| train-AverageDiscoun... | -39.1        |
| train-AverageReturn     | -61.2        |
| train-EnvExecTime       | 2.74         |
| train-MaxReturn         | -58.6        |
| train-MinReturn         | -64.5        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14           |
| train-StdReturn         | 1.22         |
------------------------------------------

 ---------------- Iteration 229 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 229          |
| ItrTime                 | 17.2         |
| LossAfter               | -0.031198932 |
| LossBefore              | -0.006441144 |
| Time                    | 3.96e+03     |
| Time-Optimization       | 0.252        |
| Time-SampleProc         | 0.021        |
| Time-Sampling           | 16.9         |
| n_timesteps             | 2300000      |
| train-AverageDiscoun... | -39.2        |
| train-AverageReturn     | -61.2        |
| train-EnvExecTime       | 2.66         |
| train-MaxReturn         | -58.1        |
| train-MinReturn         | -63.1        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14           |
| train-StdReturn         | 0.927        |
------------------------------------------

 ---------------- Iteration 230 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 230           |
| ItrTime                 | 17.2          |
| LossAfter               | -0.0010549927 |
| LossBefore              | 0.009652338   |
| Time                    | 3.98e+03      |
| Time-Optimization       | 0.256         |
| Time-SampleProc         | 0.027         |
| Time-Sampling           | 16.9          |
| n_timesteps             | 2310000       |
| train-AverageDiscoun... | -39.5         |
| train-AverageReturn     | -61.6         |
| train-EnvExecTime       | 2.65          |
| train-MaxReturn         | -59.7         |
| train-MinReturn         | -64.1         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 13.9          |
| train-StdReturn         | 0.993         |
-------------------------------------------

 ---------------- Iteration 231 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 231          |
| ItrTime                 | 17.3         |
| LossAfter               | 0.0062811463 |
| LossBefore              | 0.018512152  |
| Time                    | 3.99e+03     |
| Time-Optimization       | 0.253        |
| Time-SampleProc         | 0.029        |
| Time-Sampling           | 17           |
| n_timesteps             | 2320000      |
| train-AverageDiscoun... | -39.3        |
| train-AverageReturn     | -61.3        |
| train-EnvExecTime       | 2.68         |
| train-MaxReturn         | -58.2        |
| train-MinReturn         | -64.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14           |
| train-StdReturn         | 1.05         |
------------------------------------------

 ---------------- Iteration 232 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 232          |
| ItrTime                 | 17.4         |
| LossAfter               | -0.018458633 |
| LossBefore              | -0.006951369 |
| Time                    | 4.01e+03     |
| Time-Optimization       | 0.255        |
| Time-SampleProc         | 0.022        |
| Time-Sampling           | 17.1         |
| n_timesteps             | 2330000      |
| train-AverageDiscoun... | -39.2        |
| train-AverageReturn     | -61.2        |
| train-EnvExecTime       | 2.77         |
| train-MaxReturn         | -58.5        |
| train-MinReturn         | -64.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 1.19         |
------------------------------------------

 ---------------- Iteration 233 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 233          |
| ItrTime                 | 17.4         |
| LossAfter               | -0.037061848 |
| LossBefore              | -0.010166974 |
| Time                    | 4.03e+03     |
| Time-Optimization       | 0.256        |
| Time-SampleProc         | 0.027        |
| Time-Sampling           | 17.1         |
| n_timesteps             | 2340000      |
| train-AverageDiscoun... | -39.2        |
| train-AverageReturn     | -61.2        |
| train-EnvExecTime       | 2.69         |
| train-MaxReturn         | -57.9        |
| train-MinReturn         | -63.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 1.18         |
------------------------------------------

 ---------------- Iteration 234 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 234         |
| ItrTime                 | 17.1        |
| LossAfter               | -0.03071186 |
| LossBefore              | 0.009727556 |
| Time                    | 4.05e+03    |
| Time-Optimization       | 0.27        |
| Time-SampleProc         | 0.022       |
| Time-Sampling           | 16.8        |
| n_timesteps             | 2350000     |
| train-AverageDiscoun... | -39.4       |
| train-AverageReturn     | -61.4       |
| train-EnvExecTime       | 2.6         |
| train-MaxReturn         | -58.1       |
| train-MinReturn         | -64.4       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 13.9        |
| train-StdReturn         | 1.15        |
-----------------------------------------

 ---------------- Iteration 235 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 235          |
| ItrTime                 | 17.5         |
| LossAfter               | -0.011704187 |
| LossBefore              | 0.004863101  |
| Time                    | 4.06e+03     |
| Time-Optimization       | 0.258        |
| Time-SampleProc         | 0.023        |
| Time-Sampling           | 17.2         |
| n_timesteps             | 2360000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.4        |
| train-EnvExecTime       | 2.75         |
| train-MaxReturn         | -58.3        |
| train-MinReturn         | -64.7        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 1.14         |
------------------------------------------

 ---------------- Iteration 236 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 236           |
| ItrTime                 | 17.1          |
| LossAfter               | -0.026768604  |
| LossBefore              | -0.0072353333 |
| Time                    | 4.08e+03      |
| Time-Optimization       | 0.261         |
| Time-SampleProc         | 0.029         |
| Time-Sampling           | 16.8          |
| n_timesteps             | 2370000       |
| train-AverageDiscoun... | -39.4         |
| train-AverageReturn     | -61.5         |
| train-EnvExecTime       | 2.66          |
| train-MaxReturn         | -58.7         |
| train-MinReturn         | -64.4         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 13.9          |
| train-StdReturn         | 1.16          |
-------------------------------------------

 ---------------- Iteration 237 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 237         |
| ItrTime                 | 17.5        |
| LossAfter               | -0.00050737 |
| LossBefore              | 0.016990976 |
| Time                    | 4.1e+03     |
| Time-Optimization       | 0.255       |
| Time-SampleProc         | 0.026       |
| Time-Sampling           | 17.3        |
| n_timesteps             | 2380000     |
| train-AverageDiscoun... | -39.4       |
| train-AverageReturn     | -61.4       |
| train-EnvExecTime       | 2.78        |
| train-MaxReturn         | -58.5       |
| train-MinReturn         | -65.1       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.2        |
| train-StdReturn         | 1.26        |
-----------------------------------------

 ---------------- Iteration 238 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 238          |
| ItrTime                 | 17.2         |
| LossAfter               | -0.014205091 |
| LossBefore              | 0.00706228   |
| Time                    | 4.11e+03     |
| Time-Optimization       | 0.261        |
| Time-SampleProc         | 0.03         |
| Time-Sampling           | 16.9         |
| n_timesteps             | 2390000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.68         |
| train-MaxReturn         | -57.9        |
| train-MinReturn         | -65          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14           |
| train-StdReturn         | 1.18         |
------------------------------------------

 ---------------- Iteration 239 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 239         |
| ItrTime                 | 17.2        |
| LossAfter               | -0.01267749 |
| LossBefore              | 0.033711437 |
| Time                    | 4.13e+03    |
| Time-Optimization       | 0.262       |
| Time-SampleProc         | 0.025       |
| Time-Sampling           | 16.9        |
| n_timesteps             | 2400000     |
| train-AverageDiscoun... | -39.4       |
| train-AverageReturn     | -61.5       |
| train-EnvExecTime       | 2.69        |
| train-MaxReturn         | -58.5       |
| train-MinReturn         | -64.3       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 13.9        |
| train-StdReturn         | 1.19        |
-----------------------------------------

 ---------------- Iteration 240 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 240          |
| ItrTime                 | 17.4         |
| LossAfter               | -0.02345141  |
| LossBefore              | -0.011534543 |
| Time                    | 4.15e+03     |
| Time-Optimization       | 0.257        |
| Time-SampleProc         | 0.027        |
| Time-Sampling           | 17.2         |
| n_timesteps             | 2410000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.4        |
| train-EnvExecTime       | 2.73         |
| train-MaxReturn         | -58.7        |
| train-MinReturn         | -64.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 1.1          |
------------------------------------------

 ---------------- Iteration 241 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 241          |
| ItrTime                 | 17.7         |
| LossAfter               | 0.0027674744 |
| LossBefore              | 0.013876141  |
| Time                    | 4.17e+03     |
| Time-Optimization       | 0.269        |
| Time-SampleProc         | 0.026        |
| Time-Sampling           | 17.4         |
| n_timesteps             | 2420000      |
| train-AverageDiscoun... | -39.5        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.84         |
| train-MaxReturn         | -57.5        |
| train-MinReturn         | -64.3        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.3         |
| train-StdReturn         | 1.1          |
------------------------------------------

 ---------------- Iteration 242 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 242          |
| ItrTime                 | 17.1         |
| LossAfter               | -0.013866477 |
| LossBefore              | 0.005619563  |
| Time                    | 4.18e+03     |
| Time-Optimization       | 0.255        |
| Time-SampleProc         | 0.022        |
| Time-Sampling           | 16.9         |
| n_timesteps             | 2430000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.68         |
| train-MaxReturn         | -58          |
| train-MinReturn         | -63.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.9         |
| train-StdReturn         | 1.1          |
------------------------------------------

 ---------------- Iteration 243 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 243           |
| ItrTime                 | 17.2          |
| LossAfter               | -0.030811511  |
| LossBefore              | -0.0107956175 |
| Time                    | 4.2e+03       |
| Time-Optimization       | 0.263         |
| Time-SampleProc         | 0.025         |
| Time-Sampling           | 16.9          |
| n_timesteps             | 2440000       |
| train-AverageDiscoun... | -39.4         |
| train-AverageReturn     | -61.4         |
| train-EnvExecTime       | 2.66          |
| train-MaxReturn         | -59.2         |
| train-MinReturn         | -64.2         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 13.9          |
| train-StdReturn         | 1.04          |
-------------------------------------------

 ---------------- Iteration 244 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 244           |
| ItrTime                 | 17.2          |
| LossAfter               | -0.020186197  |
| LossBefore              | -0.0055306368 |
| Time                    | 4.22e+03      |
| Time-Optimization       | 0.255         |
| Time-SampleProc         | 0.026         |
| Time-Sampling           | 16.9          |
| n_timesteps             | 2450000       |
| train-AverageDiscoun... | -39.5         |
| train-AverageReturn     | -61.6         |
| train-EnvExecTime       | 2.74          |
| train-MaxReturn         | -59           |
| train-MinReturn         | -65.3         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 13.9          |
| train-StdReturn         | 1.14          |
-------------------------------------------

 ---------------- Iteration 245 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 245           |
| ItrTime                 | 17.2          |
| LossAfter               | -0.0011172363 |
| LossBefore              | 0.0069786804  |
| Time                    | 4.24e+03      |
| Time-Optimization       | 0.264         |
| Time-SampleProc         | 0.022         |
| Time-Sampling           | 16.9          |
| n_timesteps             | 2460000       |
| train-AverageDiscoun... | -39.4         |
| train-AverageReturn     | -61.4         |
| train-EnvExecTime       | 2.78          |
| train-MaxReturn         | -57.3         |
| train-MinReturn         | -64.6         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 13.8          |
| train-StdReturn         | 1.23          |
-------------------------------------------

 ---------------- Iteration 246 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 246          |
| ItrTime                 | 17.1         |
| LossAfter               | -0.022389265 |
| LossBefore              | 0.011483353  |
| Time                    | 4.25e+03     |
| Time-Optimization       | 0.26         |
| Time-SampleProc         | 0.022        |
| Time-Sampling           | 16.9         |
| n_timesteps             | 2470000      |
| train-AverageDiscoun... | -39.3        |
| train-AverageReturn     | -61.3        |
| train-EnvExecTime       | 2.67         |
| train-MaxReturn         | -59.1        |
| train-MinReturn         | -65.1        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.9         |
| train-StdReturn         | 1.23         |
------------------------------------------

 ---------------- Iteration 247 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 247          |
| ItrTime                 | 17.1         |
| LossAfter               | -0.024170117 |
| LossBefore              | 0.024050104  |
| Time                    | 4.27e+03     |
| Time-Optimization       | 0.259        |
| Time-SampleProc         | 0.029        |
| Time-Sampling           | 16.8         |
| n_timesteps             | 2480000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.67         |
| train-MaxReturn         | -57.2        |
| train-MinReturn         | -65.3        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.9         |
| train-StdReturn         | 1.34         |
------------------------------------------

 ---------------- Iteration 248 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 248          |
| ItrTime                 | 17.1         |
| LossAfter               | -0.020073045 |
| LossBefore              | -0.011572072 |
| Time                    | 4.29e+03     |
| Time-Optimization       | 0.256        |
| Time-SampleProc         | 0.029        |
| Time-Sampling           | 16.9         |
| n_timesteps             | 2490000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.72         |
| train-MaxReturn         | -58.9        |
| train-MinReturn         | -64.7        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.9         |
| train-StdReturn         | 1.19         |
------------------------------------------

 ---------------- Iteration 249 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 249         |
| ItrTime                 | 17.2        |
| LossAfter               | 0.026388714 |
| LossBefore              | 0.047276415 |
| Time                    | 4.3e+03     |
| Time-Optimization       | 0.259       |
| Time-SampleProc         | 0.021       |
| Time-Sampling           | 16.9        |
| n_timesteps             | 2500000     |
| train-AverageDiscoun... | -39.5       |
| train-AverageReturn     | -61.6       |
| train-EnvExecTime       | 2.74        |
| train-MaxReturn         | -58.8       |
| train-MinReturn         | -63.8       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 13.9        |
| train-StdReturn         | 1.15        |
-----------------------------------------

 ---------------- Iteration 250 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 250           |
| ItrTime                 | 17.4          |
| LossAfter               | -0.033745125  |
| LossBefore              | -0.0014040405 |
| Time                    | 4.32e+03      |
| Time-Optimization       | 0.262         |
| Time-SampleProc         | 0.028         |
| Time-Sampling           | 17.1          |
| n_timesteps             | 2510000       |
| train-AverageDiscoun... | -39.4         |
| train-AverageReturn     | -61.5         |
| train-EnvExecTime       | 2.7           |
| train-MaxReturn         | -59           |
| train-MinReturn         | -63.7         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.2          |
| train-StdReturn         | 1.01          |
-------------------------------------------

 ---------------- Iteration 251 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 251         |
| ItrTime                 | 17.6        |
| LossAfter               | -0.04593534 |
| LossBefore              | 0.005187073 |
| Time                    | 4.34e+03    |
| Time-Optimization       | 0.265       |
| Time-SampleProc         | 0.023       |
| Time-Sampling           | 17.3        |
| n_timesteps             | 2520000     |
| train-AverageDiscoun... | -39.2       |
| train-AverageReturn     | -61.2       |
| train-EnvExecTime       | 2.78        |
| train-MaxReturn         | -58         |
| train-MinReturn         | -63.9       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.2        |
| train-StdReturn         | 1.16        |
-----------------------------------------

 ---------------- Iteration 252 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 252          |
| ItrTime                 | 17           |
| LossAfter               | -0.030926798 |
| LossBefore              | 0.0059723267 |
| Time                    | 4.36e+03     |
| Time-Optimization       | 0.254        |
| Time-SampleProc         | 0.024        |
| Time-Sampling           | 16.8         |
| n_timesteps             | 2530000      |
| train-AverageDiscoun... | -39.5        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.62         |
| train-MaxReturn         | -58.6        |
| train-MinReturn         | -64.4        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.9         |
| train-StdReturn         | 1.12         |
------------------------------------------

 ---------------- Iteration 253 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 253          |
| ItrTime                 | 17.7         |
| LossAfter               | -0.031070178 |
| LossBefore              | -0.005503058 |
| Time                    | 4.37e+03     |
| Time-Optimization       | 0.256        |
| Time-SampleProc         | 0.027        |
| Time-Sampling           | 17.5         |
| n_timesteps             | 2540000      |
| train-AverageDiscoun... | -39.6        |
| train-AverageReturn     | -61.6        |
| train-EnvExecTime       | 2.83         |
| train-MaxReturn         | -58.8        |
| train-MinReturn         | -65.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.4         |
| train-StdReturn         | 1.19         |
------------------------------------------

 ---------------- Iteration 254 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 254          |
| ItrTime                 | 17.5         |
| LossAfter               | -0.039750554 |
| LossBefore              | 0.003254413  |
| Time                    | 4.39e+03     |
| Time-Optimization       | 0.253        |
| Time-SampleProc         | 0.026        |
| Time-Sampling           | 17.3         |
| n_timesteps             | 2550000      |
| train-AverageDiscoun... | -39.2        |
| train-AverageReturn     | -61.3        |
| train-EnvExecTime       | 2.74         |
| train-MaxReturn         | -58          |
| train-MinReturn         | -64.5        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.3         |
| train-StdReturn         | 1.07         |
------------------------------------------

 ---------------- Iteration 255 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 255          |
| ItrTime                 | 17.5         |
| LossAfter               | -0.00568667  |
| LossBefore              | 0.0066580568 |
| Time                    | 4.41e+03     |
| Time-Optimization       | 0.256        |
| Time-SampleProc         | 0.025        |
| Time-Sampling           | 17.2         |
| n_timesteps             | 2560000      |
| train-AverageDiscoun... | -39.5        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.74         |
| train-MaxReturn         | -59.3        |
| train-MinReturn         | -64.3        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 1.08         |
------------------------------------------

 ---------------- Iteration 256 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 256           |
| ItrTime                 | 17.5          |
| LossAfter               | 0.00066565245 |
| LossBefore              | 0.03306803    |
| Time                    | 4.43e+03      |
| Time-Optimization       | 0.256         |
| Time-SampleProc         | 0.028         |
| Time-Sampling           | 17.2          |
| n_timesteps             | 2570000       |
| train-AverageDiscoun... | -39.4         |
| train-AverageReturn     | -61.5         |
| train-EnvExecTime       | 2.69          |
| train-MaxReturn         | -57.8         |
| train-MinReturn         | -64.6         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.2          |
| train-StdReturn         | 1.2           |
-------------------------------------------

 ---------------- Iteration 257 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 257          |
| ItrTime                 | 17.3         |
| LossAfter               | -0.08151297  |
| LossBefore              | -0.020512557 |
| Time                    | 4.44e+03     |
| Time-Optimization       | 0.259        |
| Time-SampleProc         | 0.022        |
| Time-Sampling           | 17.1         |
| n_timesteps             | 2580000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.4        |
| train-EnvExecTime       | 2.65         |
| train-MaxReturn         | -58.3        |
| train-MinReturn         | -64.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 1.2          |
------------------------------------------

 ---------------- Iteration 258 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 258         |
| ItrTime                 | 17.5        |
| LossAfter               | -0.04079592 |
| LossBefore              | 0.01454628  |
| Time                    | 4.46e+03    |
| Time-Optimization       | 0.253       |
| Time-SampleProc         | 0.029       |
| Time-Sampling           | 17.2        |
| n_timesteps             | 2590000     |
| train-AverageDiscoun... | -39.5       |
| train-AverageReturn     | -61.6       |
| train-EnvExecTime       | 2.66        |
| train-MaxReturn         | -58.1       |
| train-MinReturn         | -64.3       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.3        |
| train-StdReturn         | 1.17        |
-----------------------------------------

 ---------------- Iteration 259 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 259          |
| ItrTime                 | 17.6         |
| LossAfter               | -0.03550514  |
| LossBefore              | -0.012126318 |
| Time                    | 4.48e+03     |
| Time-Optimization       | 0.254        |
| Time-SampleProc         | 0.025        |
| Time-Sampling           | 17.3         |
| n_timesteps             | 2600000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.4        |
| train-EnvExecTime       | 2.76         |
| train-MaxReturn         | -58.3        |
| train-MinReturn         | -63.9        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.3         |
| train-StdReturn         | 1.16         |
------------------------------------------

 ---------------- Iteration 260 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 260          |
| ItrTime                 | 17.3         |
| LossAfter               | -0.012341112 |
| LossBefore              | 0.0032922027 |
| Time                    | 4.5e+03      |
| Time-Optimization       | 0.254        |
| Time-SampleProc         | 0.026        |
| Time-Sampling           | 17.1         |
| n_timesteps             | 2610000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.69         |
| train-MaxReturn         | -58.8        |
| train-MinReturn         | -64.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 1.07         |
------------------------------------------

 ---------------- Iteration 261 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 261          |
| ItrTime                 | 17.4         |
| LossAfter               | -0.054573152 |
| LossBefore              | -0.01665821  |
| Time                    | 4.51e+03     |
| Time-Optimization       | 0.254        |
| Time-SampleProc         | 0.03         |
| Time-Sampling           | 17.1         |
| n_timesteps             | 2620000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.4        |
| train-EnvExecTime       | 2.74         |
| train-MaxReturn         | -58.8        |
| train-MinReturn         | -65.4        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 1.14         |
------------------------------------------

 ---------------- Iteration 262 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 262          |
| ItrTime                 | 17.5         |
| LossAfter               | -0.014053821 |
| LossBefore              | 0.017600501  |
| Time                    | 4.53e+03     |
| Time-Optimization       | 0.251        |
| Time-SampleProc         | 0.028        |
| Time-Sampling           | 17.3         |
| n_timesteps             | 2630000      |
| train-AverageDiscoun... | -39.5        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.72         |
| train-MaxReturn         | -59.2        |
| train-MinReturn         | -64          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.3         |
| train-StdReturn         | 0.952        |
------------------------------------------

 ---------------- Iteration 263 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 263           |
| ItrTime                 | 17.6          |
| LossAfter               | -0.0066026365 |
| LossBefore              | 0.01933528    |
| Time                    | 4.55e+03      |
| Time-Optimization       | 0.261         |
| Time-SampleProc         | 0.03          |
| Time-Sampling           | 17.3          |
| n_timesteps             | 2640000       |
| train-AverageDiscoun... | -39.4         |
| train-AverageReturn     | -61.5         |
| train-EnvExecTime       | 2.72          |
| train-MaxReturn         | -59.3         |
| train-MinReturn         | -65.3         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.3          |
| train-StdReturn         | 1.07          |
-------------------------------------------

 ---------------- Iteration 264 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 264           |
| ItrTime                 | 17.2          |
| LossAfter               | -0.0519827    |
| LossBefore              | -0.0107285585 |
| Time                    | 4.57e+03      |
| Time-Optimization       | 0.26          |
| Time-SampleProc         | 0.026         |
| Time-Sampling           | 17            |
| n_timesteps             | 2650000       |
| train-AverageDiscoun... | -39.4         |
| train-AverageReturn     | -61.4         |
| train-EnvExecTime       | 2.68          |
| train-MaxReturn         | -57.9         |
| train-MinReturn         | -64.3         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14            |
| train-StdReturn         | 1.18          |
-------------------------------------------

 ---------------- Iteration 265 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 265         |
| ItrTime                 | 17.1        |
| LossAfter               | 0.01656358  |
| LossBefore              | 0.027013373 |
| Time                    | 4.58e+03    |
| Time-Optimization       | 0.258       |
| Time-SampleProc         | 0.028       |
| Time-Sampling           | 16.8        |
| n_timesteps             | 2660000     |
| train-AverageDiscoun... | -39.2       |
| train-AverageReturn     | -61.3       |
| train-EnvExecTime       | 2.67        |
| train-MaxReturn         | -58         |
| train-MinReturn         | -64.9       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 13.9        |
| train-StdReturn         | 1.19        |
-----------------------------------------

 ---------------- Iteration 266 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 266          |
| ItrTime                 | 17           |
| LossAfter               | 0.0063418825 |
| LossBefore              | 0.02833213   |
| Time                    | 4.6e+03      |
| Time-Optimization       | 0.262        |
| Time-SampleProc         | 0.039        |
| Time-Sampling           | 16.7         |
| n_timesteps             | 2670000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.71         |
| train-MaxReturn         | -59.3        |
| train-MinReturn         | -64.9        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.7         |
| train-StdReturn         | 1.12         |
------------------------------------------

 ---------------- Iteration 267 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 267          |
| ItrTime                 | 17.3         |
| LossAfter               | -0.016496351 |
| LossBefore              | 0.016803687  |
| Time                    | 4.62e+03     |
| Time-Optimization       | 0.265        |
| Time-SampleProc         | 0.021        |
| Time-Sampling           | 17           |
| n_timesteps             | 2680000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.4        |
| train-EnvExecTime       | 2.72         |
| train-MaxReturn         | -57.5        |
| train-MinReturn         | -63.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.9         |
| train-StdReturn         | 1.1          |
------------------------------------------

 ---------------- Iteration 268 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 268          |
| ItrTime                 | 17.6         |
| LossAfter               | -0.020424707 |
| LossBefore              | 0.001235028  |
| Time                    | 4.64e+03     |
| Time-Optimization       | 0.261        |
| Time-SampleProc         | 0.022        |
| Time-Sampling           | 17.3         |
| n_timesteps             | 2690000      |
| train-AverageDiscoun... | -39.5        |
| train-AverageReturn     | -61.6        |
| train-EnvExecTime       | 2.75         |
| train-MaxReturn         | -59.1        |
| train-MinReturn         | -64.3        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.3         |
| train-StdReturn         | 1.03         |
------------------------------------------

 ---------------- Iteration 269 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 269         |
| ItrTime                 | 17.1        |
| LossAfter               | -0.03302481 |
| LossBefore              | 0.000710675 |
| Time                    | 4.65e+03    |
| Time-Optimization       | 0.26        |
| Time-SampleProc         | 0.0279      |
| Time-Sampling           | 16.8        |
| n_timesteps             | 2700000     |
| train-AverageDiscoun... | -39.3       |
| train-AverageReturn     | -61.4       |
| train-EnvExecTime       | 2.71        |
| train-MaxReturn         | -58.8       |
| train-MinReturn         | -65.7       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 13.8        |
| train-StdReturn         | 1.24        |
-----------------------------------------

 ---------------- Iteration 270 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 270           |
| ItrTime                 | 17.5          |
| LossAfter               | -0.0130029265 |
| LossBefore              | 0.006190295   |
| Time                    | 4.67e+03      |
| Time-Optimization       | 0.281         |
| Time-SampleProc         | 0.027         |
| Time-Sampling           | 17.2          |
| n_timesteps             | 2710000       |
| train-AverageDiscoun... | -39.4         |
| train-AverageReturn     | -61.5         |
| train-EnvExecTime       | 2.71          |
| train-MaxReturn         | -59.2         |
| train-MinReturn         | -64.9         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.2          |
| train-StdReturn         | 1.04          |
-------------------------------------------

 ---------------- Iteration 271 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 271          |
| ItrTime                 | 17.4         |
| LossAfter               | -0.033170935 |
| LossBefore              | 0.0043641906 |
| Time                    | 4.69e+03     |
| Time-Optimization       | 0.254        |
| Time-SampleProc         | 0.021        |
| Time-Sampling           | 17.1         |
| n_timesteps             | 2720000      |
| train-AverageDiscoun... | -39.5        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.7          |
| train-MaxReturn         | -58.8        |
| train-MinReturn         | -63.9        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 0.971        |
------------------------------------------

 ---------------- Iteration 272 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 272          |
| ItrTime                 | 17.5         |
| LossAfter               | -0.019374328 |
| LossBefore              | 0.0036901734 |
| Time                    | 4.7e+03      |
| Time-Optimization       | 0.254        |
| Time-SampleProc         | 0.021        |
| Time-Sampling           | 17.2         |
| n_timesteps             | 2730000      |
| train-AverageDiscoun... | -39.3        |
| train-AverageReturn     | -61.4        |
| train-EnvExecTime       | 2.73         |
| train-MaxReturn         | -57.9        |
| train-MinReturn         | -64.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 1.2          |
------------------------------------------

 ---------------- Iteration 273 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 273          |
| ItrTime                 | 17.1         |
| LossAfter               | -0.031370588 |
| LossBefore              | -0.012267586 |
| Time                    | 4.72e+03     |
| Time-Optimization       | 0.254        |
| Time-SampleProc         | 0.026        |
| Time-Sampling           | 16.8         |
| n_timesteps             | 2740000      |
| train-AverageDiscoun... | -39.5        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.64         |
| train-MaxReturn         | -59          |
| train-MinReturn         | -65.4        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.9         |
| train-StdReturn         | 1.13         |
------------------------------------------

 ---------------- Iteration 274 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 274          |
| ItrTime                 | 17.5         |
| LossAfter               | -0.04545892  |
| LossBefore              | -0.015172336 |
| Time                    | 4.74e+03     |
| Time-Optimization       | 0.26         |
| Time-SampleProc         | 0.027        |
| Time-Sampling           | 17.2         |
| n_timesteps             | 2750000      |
| train-AverageDiscoun... | -39.2        |
| train-AverageReturn     | -61.2        |
| train-EnvExecTime       | 2.68         |
| train-MaxReturn         | -58.1        |
| train-MinReturn         | -64.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.3         |
| train-StdReturn         | 1.05         |
------------------------------------------

 ---------------- Iteration 275 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 275          |
| ItrTime                 | 17.5         |
| LossAfter               | -0.030038636 |
| LossBefore              | 0.006004907  |
| Time                    | 4.76e+03     |
| Time-Optimization       | 0.262        |
| Time-SampleProc         | 0.029        |
| Time-Sampling           | 17.2         |
| n_timesteps             | 2760000      |
| train-AverageDiscoun... | -39.6        |
| train-AverageReturn     | -61.6        |
| train-EnvExecTime       | 2.64         |
| train-MaxReturn         | -58.3        |
| train-MinReturn         | -63.9        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.3         |
| train-StdReturn         | 1.13         |
------------------------------------------

 ---------------- Iteration 276 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 276          |
| ItrTime                 | 17.1         |
| LossAfter               | -0.04903413  |
| LossBefore              | -0.029031133 |
| Time                    | 4.77e+03     |
| Time-Optimization       | 0.254        |
| Time-SampleProc         | 0.029        |
| Time-Sampling           | 16.8         |
| n_timesteps             | 2770000      |
| train-AverageDiscoun... | -39.2        |
| train-AverageReturn     | -61.3        |
| train-EnvExecTime       | 2.71         |
| train-MaxReturn         | -58.2        |
| train-MinReturn         | -64.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.9         |
| train-StdReturn         | 1.2          |
------------------------------------------

 ---------------- Iteration 277 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 277          |
| ItrTime                 | 17.7         |
| LossAfter               | -0.05504919  |
| LossBefore              | -0.016936142 |
| Time                    | 4.79e+03     |
| Time-Optimization       | 0.256        |
| Time-SampleProc         | 0.028        |
| Time-Sampling           | 17.4         |
| n_timesteps             | 2780000      |
| train-AverageDiscoun... | -39.5        |
| train-AverageReturn     | -61.6        |
| train-EnvExecTime       | 2.72         |
| train-MaxReturn         | -59          |
| train-MinReturn         | -65.7        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.4         |
| train-StdReturn         | 1.31         |
------------------------------------------

 ---------------- Iteration 278 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 278          |
| ItrTime                 | 17.5         |
| LossAfter               | -0.013504145 |
| LossBefore              | 0.02478253   |
| Time                    | 4.81e+03     |
| Time-Optimization       | 0.259        |
| Time-SampleProc         | 0.025        |
| Time-Sampling           | 17.2         |
| n_timesteps             | 2790000      |
| train-AverageDiscoun... | -39.5        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.7          |
| train-MaxReturn         | -58.8        |
| train-MinReturn         | -64.5        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 1.13         |
------------------------------------------

 ---------------- Iteration 279 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 279           |
| ItrTime                 | 17.5          |
| LossAfter               | -0.039649464  |
| LossBefore              | -0.0027540345 |
| Time                    | 4.83e+03      |
| Time-Optimization       | 0.27          |
| Time-SampleProc         | 0.021         |
| Time-Sampling           | 17.2          |
| n_timesteps             | 2800000       |
| train-AverageDiscoun... | -39.3         |
| train-AverageReturn     | -61.4         |
| train-EnvExecTime       | 2.76          |
| train-MaxReturn         | -58.2         |
| train-MinReturn         | -64.6         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.1          |
| train-StdReturn         | 1.09          |
-------------------------------------------

 ---------------- Iteration 280 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 280          |
| ItrTime                 | 17.4         |
| LossAfter               | -0.026512701 |
| LossBefore              | -0.004460489 |
| Time                    | 4.84e+03     |
| Time-Optimization       | 0.251        |
| Time-SampleProc         | 0.028        |
| Time-Sampling           | 17.1         |
| n_timesteps             | 2810000      |
| train-AverageDiscoun... | -39.3        |
| train-AverageReturn     | -61.4        |
| train-EnvExecTime       | 2.75         |
| train-MaxReturn         | -58.7        |
| train-MinReturn         | -66          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 1.38         |
------------------------------------------

 ---------------- Iteration 281 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 281         |
| ItrTime                 | 17.2        |
| LossAfter               | 0.018482912 |
| LossBefore              | 0.047277324 |
| Time                    | 4.86e+03    |
| Time-Optimization       | 0.26        |
| Time-SampleProc         | 0.026       |
| Time-Sampling           | 16.9        |
| n_timesteps             | 2820000     |
| train-AverageDiscoun... | -39.4       |
| train-AverageReturn     | -61.5       |
| train-EnvExecTime       | 2.72        |
| train-MaxReturn         | -58.8       |
| train-MinReturn         | -64.4       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 13.9        |
| train-StdReturn         | 1.1         |
-----------------------------------------

 ---------------- Iteration 282 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 282           |
| ItrTime                 | 17.2          |
| LossAfter               | -0.017884204  |
| LossBefore              | -0.0025700256 |
| Time                    | 4.88e+03      |
| Time-Optimization       | 0.256         |
| Time-SampleProc         | 0.03          |
| Time-Sampling           | 16.9          |
| n_timesteps             | 2830000       |
| train-AverageDiscoun... | -39.5         |
| train-AverageReturn     | -61.6         |
| train-EnvExecTime       | 2.67          |
| train-MaxReturn         | -58.1         |
| train-MinReturn         | -64.9         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14            |
| train-StdReturn         | 1.11          |
-------------------------------------------

 ---------------- Iteration 283 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 283          |
| ItrTime                 | 17.6         |
| LossAfter               | -0.054404344 |
| LossBefore              | -0.013840644 |
| Time                    | 4.9e+03      |
| Time-Optimization       | 0.256        |
| Time-SampleProc         | 0.022        |
| Time-Sampling           | 17.3         |
| n_timesteps             | 2840000      |
| train-AverageDiscoun... | -39.5        |
| train-AverageReturn     | -61.6        |
| train-EnvExecTime       | 2.78         |
| train-MaxReturn         | -58.5        |
| train-MinReturn         | -65.1        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.3         |
| train-StdReturn         | 1.07         |
------------------------------------------

 ---------------- Iteration 284 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 284          |
| ItrTime                 | 17.4         |
| LossAfter               | -0.063632414 |
| LossBefore              | -0.021063555 |
| Time                    | 4.91e+03     |
| Time-Optimization       | 0.256        |
| Time-SampleProc         | 0.025        |
| Time-Sampling           | 17.1         |
| n_timesteps             | 2850000      |
| train-AverageDiscoun... | -39.5        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.61         |
| train-MaxReturn         | -59.5        |
| train-MinReturn         | -64.4        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.3         |
| train-StdReturn         | 1.04         |
------------------------------------------

 ---------------- Iteration 285 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 285          |
| ItrTime                 | 17.4         |
| LossAfter               | -0.052020397 |
| LossBefore              | -0.019503968 |
| Time                    | 4.93e+03     |
| Time-Optimization       | 0.256        |
| Time-SampleProc         | 0.03         |
| Time-Sampling           | 17.1         |
| n_timesteps             | 2860000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.4        |
| train-EnvExecTime       | 2.68         |
| train-MaxReturn         | -58.1        |
| train-MinReturn         | -64.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 1.2          |
------------------------------------------

 ---------------- Iteration 286 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 286          |
| ItrTime                 | 17           |
| LossAfter               | -0.026493726 |
| LossBefore              | 0.0006975769 |
| Time                    | 4.95e+03     |
| Time-Optimization       | 0.253        |
| Time-SampleProc         | 0.028        |
| Time-Sampling           | 16.7         |
| n_timesteps             | 2870000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.61         |
| train-MaxReturn         | -57.5        |
| train-MinReturn         | -64.5        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.9         |
| train-StdReturn         | 1.22         |
------------------------------------------

 ---------------- Iteration 287 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 287          |
| ItrTime                 | 17.2         |
| LossAfter               | -0.018476684 |
| LossBefore              | 0.00932713   |
| Time                    | 4.97e+03     |
| Time-Optimization       | 0.263        |
| Time-SampleProc         | 0.022        |
| Time-Sampling           | 16.9         |
| n_timesteps             | 2880000      |
| train-AverageDiscoun... | -39.5        |
| train-AverageReturn     | -61.6        |
| train-EnvExecTime       | 2.66         |
| train-MaxReturn         | -58.7        |
| train-MinReturn         | -64.3        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14           |
| train-StdReturn         | 1.02         |
------------------------------------------

 ---------------- Iteration 288 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 288           |
| ItrTime                 | 17.4          |
| LossAfter               | -0.04837029   |
| LossBefore              | -0.0041077454 |
| Time                    | 4.98e+03      |
| Time-Optimization       | 0.256         |
| Time-SampleProc         | 0.025         |
| Time-Sampling           | 17.2          |
| n_timesteps             | 2890000       |
| train-AverageDiscoun... | -39.2         |
| train-AverageReturn     | -61.2         |
| train-EnvExecTime       | 2.64          |
| train-MaxReturn         | -58.2         |
| train-MinReturn         | -63.8         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 14.3          |
| train-StdReturn         | 1.07          |
-------------------------------------------

 ---------------- Iteration 289 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 289         |
| ItrTime                 | 17.6        |
| LossAfter               | 0.014861087 |
| LossBefore              | 0.011950964 |
| Time                    | 5e+03       |
| Time-Optimization       | 0.266       |
| Time-SampleProc         | 0.021       |
| Time-Sampling           | 17.3        |
| n_timesteps             | 2900000     |
| train-AverageDiscoun... | -39.6       |
| train-AverageReturn     | -61.6       |
| train-EnvExecTime       | 2.68        |
| train-MaxReturn         | -58.2       |
| train-MinReturn         | -64.5       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14.3        |
| train-StdReturn         | 1.24        |
-----------------------------------------

 ---------------- Iteration 290 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 290          |
| ItrTime                 | 17.5         |
| LossAfter               | -0.049080737 |
| LossBefore              | -0.014624039 |
| Time                    | 5.02e+03     |
| Time-Optimization       | 0.254        |
| Time-SampleProc         | 0.022        |
| Time-Sampling           | 17.2         |
| n_timesteps             | 2910000      |
| train-AverageDiscoun... | -39.5        |
| train-AverageReturn     | -61.6        |
| train-EnvExecTime       | 2.71         |
| train-MaxReturn         | -59.2        |
| train-MinReturn         | -64.5        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.2         |
| train-StdReturn         | 1.08         |
------------------------------------------

 ---------------- Iteration 291 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 291          |
| ItrTime                 | 17.1         |
| LossAfter               | -0.040065516 |
| LossBefore              | -0.024632463 |
| Time                    | 5.04e+03     |
| Time-Optimization       | 0.255        |
| Time-SampleProc         | 0.02         |
| Time-Sampling           | 16.8         |
| n_timesteps             | 2920000      |
| train-AverageDiscoun... | -39.5        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.67         |
| train-MaxReturn         | -58.3        |
| train-MinReturn         | -65.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.9         |
| train-StdReturn         | 1.16         |
------------------------------------------

 ---------------- Iteration 292 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 292           |
| ItrTime                 | 17.1          |
| LossAfter               | -0.0053289644 |
| LossBefore              | 0.015261893   |
| Time                    | 5.05e+03      |
| Time-Optimization       | 0.255         |
| Time-SampleProc         | 0.023         |
| Time-Sampling           | 16.9          |
| n_timesteps             | 2930000       |
| train-AverageDiscoun... | -39.4         |
| train-AverageReturn     | -61.5         |
| train-EnvExecTime       | 2.68          |
| train-MaxReturn         | -58.7         |
| train-MinReturn         | -65.1         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 13.9          |
| train-StdReturn         | 1.18          |
-------------------------------------------

 ---------------- Iteration 293 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 293          |
| ItrTime                 | 17           |
| LossAfter               | -0.017557215 |
| LossBefore              | 0.014106775  |
| Time                    | 5.07e+03     |
| Time-Optimization       | 0.257        |
| Time-SampleProc         | 0.029        |
| Time-Sampling           | 16.7         |
| n_timesteps             | 2940000      |
| train-AverageDiscoun... | -39.3        |
| train-AverageReturn     | -61.3        |
| train-EnvExecTime       | 2.69         |
| train-MaxReturn         | -58.3        |
| train-MinReturn         | -64.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.7         |
| train-StdReturn         | 1.12         |
------------------------------------------

 ---------------- Iteration 294 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 294          |
| ItrTime                 | 17.1         |
| LossAfter               | -0.07512091  |
| LossBefore              | -0.010411499 |
| Time                    | 5.09e+03     |
| Time-Optimization       | 0.263        |
| Time-SampleProc         | 0.022        |
| Time-Sampling           | 16.9         |
| n_timesteps             | 2950000      |
| train-AverageDiscoun... | -39.2        |
| train-AverageReturn     | -61.2        |
| train-EnvExecTime       | 2.64         |
| train-MaxReturn         | -57.8        |
| train-MinReturn         | -64.1        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14           |
| train-StdReturn         | 1.1          |
------------------------------------------

 ---------------- Iteration 295 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 295          |
| ItrTime                 | 17.2         |
| LossAfter               | -0.053751    |
| LossBefore              | -0.045242857 |
| Time                    | 5.1e+03      |
| Time-Optimization       | 0.263        |
| Time-SampleProc         | 0.025        |
| Time-Sampling           | 16.9         |
| n_timesteps             | 2960000      |
| train-AverageDiscoun... | -39.5        |
| train-AverageReturn     | -61.6        |
| train-EnvExecTime       | 2.66         |
| train-MaxReturn         | -58.7        |
| train-MinReturn         | -64.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14           |
| train-StdReturn         | 1.09         |
------------------------------------------

 ---------------- Iteration 296 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 296          |
| ItrTime                 | 17.9         |
| LossAfter               | -0.034728687 |
| LossBefore              | -0.017440546 |
| Time                    | 5.12e+03     |
| Time-Optimization       | 0.879        |
| Time-SampleProc         | 0.026        |
| Time-Sampling           | 17           |
| n_timesteps             | 2970000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.5        |
| train-EnvExecTime       | 2.65         |
| train-MaxReturn         | -58.4        |
| train-MinReturn         | -64.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 14.1         |
| train-StdReturn         | 1.1          |
------------------------------------------

 ---------------- Iteration 297 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 297         |
| ItrTime                 | 17.3        |
| LossAfter               | -0.02230047 |
| LossBefore              | 0.010607843 |
| Time                    | 5.14e+03    |
| Time-Optimization       | 0.257       |
| Time-SampleProc         | 0.025       |
| Time-Sampling           | 17          |
| n_timesteps             | 2980000     |
| train-AverageDiscoun... | -39.4       |
| train-AverageReturn     | -61.5       |
| train-EnvExecTime       | 2.74        |
| train-MaxReturn         | -58         |
| train-MinReturn         | -64.4       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 14          |
| train-StdReturn         | 1.2         |
-----------------------------------------

 ---------------- Iteration 298 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 298           |
| ItrTime                 | 17            |
| LossAfter               | -0.080673136  |
| LossBefore              | -0.0013580932 |
| Time                    | 5.16e+03      |
| Time-Optimization       | 0.273         |
| Time-SampleProc         | 0.03          |
| Time-Sampling           | 16.7          |
| n_timesteps             | 2990000       |
| train-AverageDiscoun... | -39.4         |
| train-AverageReturn     | -61.5         |
| train-EnvExecTime       | 2.63          |
| train-MaxReturn         | -58.6         |
| train-MinReturn         | -65.2         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 13.8          |
| train-StdReturn         | 1.17          |
-------------------------------------------

 ---------------- Iteration 299 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 299          |
| ItrTime                 | 17.1         |
| LossAfter               | -0.074662    |
| LossBefore              | 0.0007370056 |
| Time                    | 5.17e+03     |
| Time-Optimization       | 0.255        |
| Time-SampleProc         | 0.024        |
| Time-Sampling           | 16.9         |
| n_timesteps             | 3000000      |
| train-AverageDiscoun... | -39.4        |
| train-AverageReturn     | -61.4        |
| train-EnvExecTime       | 2.67         |
| train-MaxReturn         | -58.7        |
| train-MinReturn         | -64.4        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 13.9         |
| train-StdReturn         | 1.01         |
------------------------------------------
Training finished
